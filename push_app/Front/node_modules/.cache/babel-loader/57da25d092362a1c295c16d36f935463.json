{"ast":null,"code":"\"use strict\"; // Copyright 2022 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.createURI = exports.upload = exports.Upload = exports.PROTOCOL_REGEX = void 0;\n\nconst abort_controller_1 = require(\"abort-controller\");\n\nconst ConfigStore = require(\"configstore\");\n\nconst crypto_1 = require(\"crypto\");\n\nconst extend = require(\"extend\");\n\nconst gaxios = require(\"gaxios\");\n\nconst google_auth_library_1 = require(\"google-auth-library\");\n\nconst Pumpify = require(\"pumpify\");\n\nconst stream_1 = require(\"stream\");\n\nconst streamEvents = require(\"stream-events\");\n\nconst retry = require(\"async-retry\");\n\nconst NOT_FOUND_STATUS_CODE = 404;\nconst TERMINATED_UPLOAD_STATUS_CODE = 410;\nconst RESUMABLE_INCOMPLETE_STATUS_CODE = 308;\nconst DEFAULT_API_ENDPOINT_REGEX = /.*\\.googleapis\\.com/;\nexports.PROTOCOL_REGEX = /^(\\w*):\\/\\//;\n\nclass Upload extends Pumpify {\n  constructor(cfg) {\n    super();\n    this.numBytesWritten = 0;\n    this.numRetries = 0;\n    this.upstreamChunkBuffer = Buffer.alloc(0);\n    this.chunkBufferEncoding = undefined;\n    this.numChunksReadInRequest = 0;\n    /**\n     * A chunk used for caching the most recent upload chunk.\n     * We should not assume that the server received all bytes sent in the request.\n     *  - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n     */\n\n    this.lastChunkSent = Buffer.alloc(0);\n    this.upstreamEnded = false;\n    /** A stream representing the incoming data to upload */\n\n    this.upstream = new stream_1.Duplex({\n      read: async () => {\n        this.once('prepareFinish', () => {\n          // Allows this (`Upload`) to finish/end once the upload has succeeded.\n          this.upstream.push(null);\n        });\n      },\n      write: this.writeToChunkBuffer.bind(this)\n    });\n    streamEvents(this);\n    cfg = cfg || {};\n\n    if (!cfg.bucket || !cfg.file) {\n      throw new Error('A bucket and file name are required');\n    }\n\n    cfg.authConfig = cfg.authConfig || {};\n    cfg.authConfig.scopes = ['https://www.googleapis.com/auth/devstorage.full_control'];\n    this.authClient = cfg.authClient || new google_auth_library_1.GoogleAuth(cfg.authConfig);\n    this.apiEndpoint = 'https://storage.googleapis.com';\n\n    if (cfg.apiEndpoint) {\n      this.apiEndpoint = this.sanitizeEndpoint(cfg.apiEndpoint);\n\n      if (!DEFAULT_API_ENDPOINT_REGEX.test(cfg.apiEndpoint)) {\n        this.authClient = gaxios;\n      }\n    }\n\n    this.baseURI = `${this.apiEndpoint}/upload/storage/v1/b`;\n    this.bucket = cfg.bucket;\n    const cacheKeyElements = [cfg.bucket, cfg.file];\n\n    if (typeof cfg.generation === 'number') {\n      cacheKeyElements.push(`${cfg.generation}`);\n    }\n\n    this.cacheKey = cacheKeyElements.join('/');\n    this.customRequestOptions = cfg.customRequestOptions || {};\n    this.file = cfg.file;\n    this.generation = cfg.generation;\n    this.kmsKeyName = cfg.kmsKeyName;\n    this.metadata = cfg.metadata || {};\n    this.offset = cfg.offset;\n    this.origin = cfg.origin;\n    this.params = cfg.params || {};\n    this.userProject = cfg.userProject;\n    this.chunkSize = cfg.chunkSize;\n    this.retryOptions = cfg.retryOptions;\n\n    if (cfg.key) {\n      /**\n       * NOTE: This is `as string` because there appears to be some weird kind\n       * of TypeScript bug as 2.8. Tracking the issue here:\n       * https://github.com/Microsoft/TypeScript/issues/23155\n       */\n      const base64Key = Buffer.from(cfg.key).toString('base64');\n      this.encryption = {\n        key: base64Key,\n        hash: crypto_1.createHash('sha256').update(cfg.key).digest('base64')\n      };\n    }\n\n    this.predefinedAcl = cfg.predefinedAcl;\n    if (cfg.private) this.predefinedAcl = 'private';\n    if (cfg.public) this.predefinedAcl = 'publicRead';\n    const configPath = cfg.configPath;\n    this.configStore = new ConfigStore('gcs-resumable-upload', null, {\n      configPath\n    });\n    const autoRetry = cfg.retryOptions.autoRetry;\n    this.uriProvidedManually = !!cfg.uri;\n    this.uri = cfg.uri || this.get('uri');\n    this.numBytesWritten = 0;\n    this.numRetries = 0; //counter for number of retries currently executed\n\n    if (!autoRetry) {\n      cfg.retryOptions.maxRetries = 0;\n    }\n\n    this.timeOfFirstRequest = Date.now();\n    const contentLength = cfg.metadata ? Number(cfg.metadata.contentLength) : NaN;\n    this.contentLength = isNaN(contentLength) ? '*' : contentLength;\n    this.upstream.on('end', () => {\n      this.upstreamEnded = true;\n    });\n    this.on('prefinish', () => {\n      this.upstreamEnded = true;\n    });\n    this.once('writing', () => {\n      // Now that someone is writing to this object, let's attach\n      // some duplexes. These duplexes enable this object to be\n      // better managed in terms of 'end'/'finish' control and\n      // buffering writes downstream if someone enables multi-\n      // chunk upload support (`chunkSize`) w/o adding too much into\n      // memory.\n      this.setPipeline(this.upstream, new stream_1.PassThrough());\n\n      if (this.uri) {\n        this.continueUploading();\n      } else {\n        this.createURI((err, uri) => {\n          if (err) {\n            return this.destroy(err);\n          }\n\n          this.set({\n            uri\n          });\n          this.startUploading();\n          return;\n        });\n      }\n    });\n  }\n  /**\n   * A handler for `upstream` to write and buffer its data.\n   *\n   * @param chunk The chunk to append to the buffer\n   * @param encoding The encoding of the chunk\n   * @param readCallback A callback for when the buffer has been read downstream\n   */\n\n\n  writeToChunkBuffer(chunk, encoding, readCallback) {\n    this.upstreamChunkBuffer = Buffer.concat([this.upstreamChunkBuffer, typeof chunk === 'string' ? Buffer.from(chunk, encoding) : chunk]);\n    this.chunkBufferEncoding = encoding;\n    this.once('readFromChunkBuffer', readCallback);\n    process.nextTick(() => this.emit('wroteToChunkBuffer'));\n  }\n  /**\n   * Prepends data back to the upstream chunk buffer.\n   *\n   * @param chunk The data to prepend\n   */\n\n\n  unshiftChunkBuffer(chunk) {\n    this.upstreamChunkBuffer = Buffer.concat([chunk, this.upstreamChunkBuffer]);\n  }\n  /**\n   * Retrieves data from upstream's buffer.\n   *\n   * @param limit The maximum amount to return from the buffer.\n   * @returns The data requested.\n   */\n\n\n  pullFromChunkBuffer(limit) {\n    const chunk = this.upstreamChunkBuffer.slice(0, limit);\n    this.upstreamChunkBuffer = this.upstreamChunkBuffer.slice(limit); // notify upstream we've read from the buffer so it can potentially\n    // send more data down.\n\n    process.nextTick(() => this.emit('readFromChunkBuffer'));\n    return chunk;\n  }\n  /**\n   * A handler for determining if data is ready to be read from upstream.\n   *\n   * @returns If there will be more chunks to read in the future\n   */\n\n\n  async waitForNextChunk() {\n    const willBeMoreChunks = await new Promise(resolve => {\n      // There's data available - it should be digested\n      if (this.upstreamChunkBuffer.byteLength) {\n        return resolve(true);\n      } // The upstream writable ended, we shouldn't expect any more data.\n\n\n      if (this.upstreamEnded) {\n        return resolve(false);\n      } // Nothing immediate seems to be determined. We need to prepare some\n      // listeners to determine next steps...\n\n\n      const wroteToChunkBufferCallback = () => {\n        removeListeners();\n        return resolve(true);\n      };\n\n      const upstreamFinishedCallback = () => {\n        removeListeners(); // this should be the last chunk, if there's anything there\n\n        if (this.upstreamChunkBuffer.length) return resolve(true);\n        return resolve(false);\n      }; // Remove listeners when we're ready to callback.\n      // It's important to clean-up listeners as Node has a default max number of\n      // event listeners. Notably, The number of requests can be greater than the\n      // number of potential listeners.\n      // - https://nodejs.org/api/events.html#eventsdefaultmaxlisteners\n\n\n      const removeListeners = () => {\n        this.removeListener('wroteToChunkBuffer', wroteToChunkBufferCallback);\n        this.upstream.removeListener('finish', upstreamFinishedCallback);\n        this.removeListener('prefinish', upstreamFinishedCallback);\n      }; // If there's data recently written it should be digested\n\n\n      this.once('wroteToChunkBuffer', wroteToChunkBufferCallback); // If the upstream finishes let's see if there's anything to grab\n\n      this.upstream.once('finish', upstreamFinishedCallback);\n      this.once('prefinish', upstreamFinishedCallback);\n    });\n    return willBeMoreChunks;\n  }\n  /**\n   * Reads data from upstream up to the provided `limit`.\n   * Ends when the limit has reached or no data is expected to be pushed from upstream.\n   *\n   * @param limit The most amount of data this iterator should return. `Infinity` by default.\n   * @param oneChunkMode Determines if one, exhaustive chunk is yielded for the iterator\n   */\n\n\n  async *upstreamIterator() {\n    let limit = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : Infinity;\n    let oneChunkMode = arguments.length > 1 ? arguments[1] : undefined;\n    let completeChunk = Buffer.alloc(0); // read from upstream chunk buffer\n\n    while (limit && (await this.waitForNextChunk())) {\n      // read until end or limit has been reached\n      const chunk = this.pullFromChunkBuffer(limit);\n      limit -= chunk.byteLength;\n\n      if (oneChunkMode) {\n        // return 1 chunk at the end of iteration\n        completeChunk = Buffer.concat([completeChunk, chunk]);\n      } else {\n        // return many chunks throughout iteration\n        yield {\n          chunk,\n          encoding: this.chunkBufferEncoding\n        };\n      }\n    }\n\n    if (oneChunkMode) {\n      yield {\n        chunk: completeChunk,\n        encoding: this.chunkBufferEncoding\n      };\n    }\n  }\n\n  createURI(callback) {\n    if (!callback) {\n      return this.createURIAsync();\n    }\n\n    this.createURIAsync().then(r => callback(null, r), callback);\n  }\n\n  async createURIAsync() {\n    const metadata = this.metadata;\n    const reqOpts = {\n      method: 'POST',\n      url: [this.baseURI, this.bucket, 'o'].join('/'),\n      params: Object.assign({\n        name: this.file,\n        uploadType: 'resumable'\n      }, this.params),\n      data: metadata,\n      headers: {}\n    };\n\n    if (metadata.contentLength) {\n      reqOpts.headers['X-Upload-Content-Length'] = metadata.contentLength.toString();\n    }\n\n    if (metadata.contentType) {\n      reqOpts.headers['X-Upload-Content-Type'] = metadata.contentType;\n    }\n\n    if (typeof this.generation !== 'undefined') {\n      reqOpts.params.ifGenerationMatch = this.generation;\n    }\n\n    if (this.kmsKeyName) {\n      reqOpts.params.kmsKeyName = this.kmsKeyName;\n    }\n\n    if (this.predefinedAcl) {\n      reqOpts.params.predefinedAcl = this.predefinedAcl;\n    }\n\n    if (this.origin) {\n      reqOpts.headers.Origin = this.origin;\n    }\n\n    const uri = await retry(async bail => {\n      var _a, _b, _c;\n\n      try {\n        const res = await this.makeRequest(reqOpts);\n        return res.headers.location;\n      } catch (err) {\n        const e = err;\n        const apiError = {\n          code: (_a = e.response) === null || _a === void 0 ? void 0 : _a.status,\n          name: (_b = e.response) === null || _b === void 0 ? void 0 : _b.statusText,\n          message: (_c = e.response) === null || _c === void 0 ? void 0 : _c.statusText,\n          errors: [{\n            reason: e.code\n          }]\n        };\n\n        if (this.retryOptions.maxRetries > 0 && this.retryOptions.retryableErrorFn(apiError)) {\n          throw e;\n        } else {\n          return bail(e);\n        }\n      }\n    }, {\n      retries: this.retryOptions.maxRetries,\n      factor: this.retryOptions.retryDelayMultiplier,\n      maxTimeout: this.retryOptions.maxRetryDelay * 1000,\n      maxRetryTime: this.retryOptions.totalTimeout * 1000\n    });\n    this.uri = uri;\n    this.offset = 0;\n    return uri;\n  }\n\n  async continueUploading() {\n    if (typeof this.offset === 'number') {\n      this.startUploading();\n      return;\n    }\n\n    await this.getAndSetOffset();\n    this.startUploading();\n  }\n\n  async startUploading() {\n    const multiChunkMode = !!this.chunkSize;\n    let responseReceived = false;\n    this.numChunksReadInRequest = 0;\n\n    if (!this.offset) {\n      this.offset = 0;\n    } // Check if we're uploading the expected object\n\n\n    if (this.numBytesWritten === 0) {\n      const isSameObject = await this.ensureUploadingSameObject();\n\n      if (!isSameObject) {\n        // `ensureUploadingSameObject` will restart the upload.\n        return;\n      }\n    } // Check if the offset (server) is too far behind the current stream\n\n\n    if (this.offset < this.numBytesWritten) {\n      this.emit('error', new RangeError('The offset is lower than the number of bytes written'));\n      return;\n    } // Check if we should 'fast-forward' to the relevant data to upload\n\n\n    if (this.numBytesWritten < this.offset) {\n      // 'fast-forward' to the byte where we need to upload.\n      // only push data from the byte after the one we left off on\n      const fastForwardBytes = this.offset - this.numBytesWritten;\n\n      for await (const _chunk of this.upstreamIterator(fastForwardBytes)) {\n        _chunk; // discard the data up until the point we want\n      }\n\n      this.numBytesWritten = this.offset;\n    }\n\n    let expectedUploadSize = undefined; // Set `expectedUploadSize` to `contentLength` if available\n\n    if (typeof this.contentLength === 'number') {\n      expectedUploadSize = this.contentLength - this.numBytesWritten;\n    } // `expectedUploadSize` should be no more than the `chunkSize`.\n    // It's possible this is the last chunk request for a multiple\n    // chunk upload, thus smaller than the chunk size.\n\n\n    if (this.chunkSize) {\n      expectedUploadSize = expectedUploadSize ? Math.min(this.chunkSize, expectedUploadSize) : this.chunkSize;\n    } // A queue for the upstream data\n\n\n    const upstreamQueue = this.upstreamIterator(expectedUploadSize, multiChunkMode // multi-chunk mode should return 1 chunk per request\n    ); // The primary read stream for this request. This stream retrieves no more\n    // than the exact requested amount from upstream.\n\n    const requestStream = new stream_1.Readable({\n      read: async () => {\n        // Don't attempt to retrieve data upstream if we already have a response\n        if (responseReceived) requestStream.push(null);\n        const result = await upstreamQueue.next();\n\n        if (result.value) {\n          this.numChunksReadInRequest++;\n          this.lastChunkSent = result.value.chunk;\n          this.numBytesWritten += result.value.chunk.byteLength;\n          this.emit('progress', {\n            bytesWritten: this.numBytesWritten,\n            contentLength: this.contentLength\n          });\n          requestStream.push(result.value.chunk, result.value.encoding);\n        }\n\n        if (result.done) {\n          requestStream.push(null);\n        }\n      }\n    });\n    let headers = {}; // If using multiple chunk upload, set appropriate header\n\n    if (multiChunkMode && expectedUploadSize) {\n      // The '-1' is because the ending byte is inclusive in the request.\n      const endingByte = expectedUploadSize + this.numBytesWritten - 1;\n      headers = {\n        'Content-Length': expectedUploadSize,\n        'Content-Range': `bytes ${this.offset}-${endingByte}/${this.contentLength}`\n      };\n    } else {\n      headers = {\n        'Content-Range': `bytes ${this.offset}-*/${this.contentLength}`\n      };\n    }\n\n    const reqOpts = {\n      method: 'PUT',\n      url: this.uri,\n      headers,\n      body: requestStream\n    };\n\n    try {\n      const resp = await this.makeRequestStream(reqOpts);\n\n      if (resp) {\n        responseReceived = true;\n        this.responseHandler(resp);\n      }\n    } catch (err) {\n      const e = err;\n      this.destroy(e);\n    }\n  } // Process the API response to look for errors that came in\n  // the response body.\n\n\n  responseHandler(resp) {\n    if (resp.data.error) {\n      this.destroy(resp.data.error);\n      return;\n    }\n\n    const shouldContinueWithNextMultiChunkRequest = this.chunkSize && resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE && resp.headers.range;\n\n    if (shouldContinueWithNextMultiChunkRequest) {\n      // Use the upper value in this header to determine where to start the next chunk.\n      // We should not assume that the server received all bytes sent in the request.\n      // https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n      const range = resp.headers.range;\n      this.offset = Number(range.split('-')[1]) + 1; // We should not assume that the server received all bytes sent in the request.\n      // - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n\n      const missingBytes = this.numBytesWritten - this.offset;\n\n      if (missingBytes) {\n        const dataToPrependForResending = this.lastChunkSent.slice(-missingBytes); // As multi-chunk uploads send one chunk per request and pulls one\n        // chunk into the pipeline, prepending the missing bytes back should\n        // be fine for the next request.\n\n        this.unshiftChunkBuffer(dataToPrependForResending);\n        this.numBytesWritten -= missingBytes;\n        this.lastChunkSent = Buffer.alloc(0);\n      } // continue uploading next chunk\n\n\n      this.continueUploading();\n    } else if (!this.isSuccessfulResponse(resp.status)) {\n      const err = {\n        code: resp.status,\n        name: 'Upload failed',\n        message: 'Upload failed'\n      };\n      this.destroy(err);\n    } else {\n      // remove the last chunk sent\n      this.lastChunkSent = Buffer.alloc(0);\n\n      if (resp && resp.data) {\n        resp.data.size = Number(resp.data.size);\n      }\n\n      this.emit('metadata', resp.data);\n      this.deleteConfig(); // Allow the object (Upload) to continue naturally so the user's\n      // \"finish\" event fires.\n\n      this.emit('prepareFinish');\n    }\n  }\n  /**\n   * Check if this is the same content uploaded previously. This caches a\n   * slice of the first chunk, then compares it with the first byte of\n   * incoming data.\n   *\n   * @returns if the request is ok to continue as-is\n   */\n\n\n  async ensureUploadingSameObject() {\n    // A queue for the upstream data\n    const upstreamQueue = this.upstreamIterator(16, true // we just want one chunk for this validation\n    );\n    const upstreamChunk = await upstreamQueue.next();\n    const chunk = upstreamChunk.value ? upstreamChunk.value.chunk : Buffer.alloc(0); // Put the original chunk back into the buffer as we just wanted to 'peek'\n    // at the stream for validation.\n\n    this.unshiftChunkBuffer(chunk);\n    let cachedFirstChunk = this.get('firstChunk');\n    const firstChunk = chunk.valueOf();\n\n    if (!cachedFirstChunk) {\n      // This is a new upload. Cache the first chunk.\n      this.set({\n        uri: this.uri,\n        firstChunk\n      });\n    } else {\n      // this continues an upload in progress. check if the bytes are the same\n      cachedFirstChunk = Buffer.from(cachedFirstChunk);\n      const nextChunk = Buffer.from(firstChunk);\n\n      if (Buffer.compare(cachedFirstChunk, nextChunk) !== 0) {\n        // this data is not the same. start a new upload\n        this.restart();\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  async getAndSetOffset() {\n    const opts = {\n      method: 'PUT',\n      url: this.uri,\n      headers: {\n        'Content-Length': 0,\n        'Content-Range': 'bytes */*'\n      }\n    };\n\n    try {\n      const resp = await this.makeRequest(opts);\n\n      if (resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE) {\n        if (resp.headers.range) {\n          const range = resp.headers.range;\n          this.offset = Number(range.split('-')[1]) + 1;\n          return;\n        }\n      }\n\n      this.offset = 0;\n    } catch (e) {\n      const err = e;\n      const resp = err.response; // we don't return a 404 to the user if they provided the resumable\n      // URI. if we're just using the configstore file to tell us that this\n      // file exists, and it turns out that it doesn't (the 404), that's\n      // probably stale config data.\n\n      if (resp && resp.status === NOT_FOUND_STATUS_CODE && !this.uriProvidedManually) {\n        this.restart();\n        return;\n      } // this resumable upload is unrecoverable (bad data or service error).\n      //  -\n      //  https://github.com/googleapis/gcs-resumable-upload/issues/15\n      //  -\n      //  https://github.com/googleapis/gcs-resumable-upload/pull/16#discussion_r80363774\n\n\n      if (resp && resp.status === TERMINATED_UPLOAD_STATUS_CODE) {\n        this.restart();\n        return;\n      }\n\n      this.destroy(err);\n    }\n  }\n\n  async makeRequest(reqOpts) {\n    if (this.encryption) {\n      reqOpts.headers = reqOpts.headers || {};\n      reqOpts.headers['x-goog-encryption-algorithm'] = 'AES256';\n      reqOpts.headers['x-goog-encryption-key'] = this.encryption.key.toString();\n      reqOpts.headers['x-goog-encryption-key-sha256'] = this.encryption.hash.toString();\n    }\n\n    if (this.userProject) {\n      reqOpts.params = reqOpts.params || {};\n      reqOpts.params.userProject = this.userProject;\n    } // Let gaxios know we will handle a 308 error code ourselves.\n\n\n    reqOpts.validateStatus = status => {\n      return this.isSuccessfulResponse(status) || status === RESUMABLE_INCOMPLETE_STATUS_CODE;\n    };\n\n    const combinedReqOpts = extend(true, {}, this.customRequestOptions, reqOpts);\n    const res = await this.authClient.request(combinedReqOpts);\n\n    if (res.data && res.data.error) {\n      throw res.data.error;\n    }\n\n    return res;\n  }\n\n  async makeRequestStream(reqOpts) {\n    const controller = new abort_controller_1.default();\n\n    const errorCallback = () => controller.abort();\n\n    this.once('error', errorCallback);\n\n    if (this.userProject) {\n      reqOpts.params = reqOpts.params || {};\n      reqOpts.params.userProject = this.userProject;\n    }\n\n    reqOpts.signal = controller.signal;\n\n    reqOpts.validateStatus = () => true;\n\n    const combinedReqOpts = extend(true, {}, this.customRequestOptions, reqOpts);\n    const res = await this.authClient.request(combinedReqOpts);\n    const successfulRequest = this.onResponse(res);\n    this.removeListener('error', errorCallback);\n    return successfulRequest ? res : null;\n  }\n\n  restart() {\n    if (this.numBytesWritten) {\n      let message = 'Attempting to restart an upload after unrecoverable bytes have been written from upstream. ';\n      message += 'Stopping as this could result in data loss. ';\n      message += 'Create a new upload object to continue.';\n      this.emit('error', new RangeError(message));\n      return;\n    }\n\n    this.lastChunkSent = Buffer.alloc(0);\n    this.deleteConfig();\n    this.createURI((err, uri) => {\n      if (err) {\n        return this.destroy(err);\n      }\n\n      this.set({\n        uri\n      });\n      this.startUploading();\n      return;\n    });\n  }\n\n  get(prop) {\n    const store = this.configStore.get(this.cacheKey);\n    return store && store[prop];\n  } // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\n  set(props) {\n    this.configStore.set(this.cacheKey, props);\n  }\n\n  deleteConfig() {\n    this.configStore.delete(this.cacheKey);\n  }\n  /**\n   * @return {bool} is the request good?\n   */\n\n\n  onResponse(resp) {\n    if (this.retryOptions.retryableErrorFn({\n      code: resp.status,\n      message: resp.statusText,\n      name: resp.statusText\n    })) {\n      this.attemptDelayedRetry(resp);\n      return false;\n    }\n\n    this.emit('response', resp);\n    return true;\n  }\n  /**\n   * @param resp GaxiosResponse object from previous attempt\n   */\n\n\n  attemptDelayedRetry(resp) {\n    if (this.numRetries < this.retryOptions.maxRetries) {\n      if (resp.status === NOT_FOUND_STATUS_CODE && this.numChunksReadInRequest === 0) {\n        this.startUploading();\n      } else {\n        const retryDelay = this.getRetryDelay();\n\n        if (retryDelay <= 0) {\n          this.destroy(new Error(`Retry total time limit exceeded - ${resp.data}`));\n          return;\n        } // Unshift the most recent chunk back in case it's needed for the next\n        // request.\n\n\n        this.numBytesWritten -= this.lastChunkSent.byteLength;\n        this.unshiftChunkBuffer(this.lastChunkSent);\n        this.lastChunkSent = Buffer.alloc(0); // We don't know how much data has been received by the server.\n        // `continueUploading` will recheck the offset via `getAndSetOffset`.\n        // If `offset` < `numberBytesReceived` then we will raise a RangeError\n        // as we've streamed too much data that has been missed - this should\n        // not be the case for multi-chunk uploads as `lastChunkSent` is the\n        // body of the entire request.\n\n        this.offset = undefined;\n        setTimeout(this.continueUploading.bind(this), retryDelay);\n      }\n\n      this.numRetries++;\n    } else {\n      this.destroy(new Error('Retry limit exceeded - ' + resp.data));\n    }\n  }\n  /**\n   * @returns {number} the amount of time to wait before retrying the request\n   */\n\n\n  getRetryDelay() {\n    const randomMs = Math.round(Math.random() * 1000);\n    const waitTime = Math.pow(this.retryOptions.retryDelayMultiplier, this.numRetries) * 1000 + randomMs;\n    const maxAllowableDelayMs = this.retryOptions.totalTimeout * 1000 - (Date.now() - this.timeOfFirstRequest);\n    const maxRetryDelayMs = this.retryOptions.maxRetryDelay * 1000;\n    return Math.min(waitTime, maxRetryDelayMs, maxAllowableDelayMs);\n  }\n  /*\n   * Prepare user-defined API endpoint for compatibility with our API.\n   */\n\n\n  sanitizeEndpoint(url) {\n    if (!exports.PROTOCOL_REGEX.test(url)) {\n      url = `https://${url}`;\n    }\n\n    return url.replace(/\\/+$/, ''); // Remove trailing slashes\n  }\n  /**\n   * Check if a given status code is 2xx\n   *\n   * @param status The status code to check\n   * @returns if the status is 2xx\n   */\n\n\n  isSuccessfulResponse(status) {\n    return status >= 200 && status < 300;\n  }\n\n}\n\nexports.Upload = Upload;\n\nfunction upload(cfg) {\n  return new Upload(cfg);\n}\n\nexports.upload = upload;\n\nfunction createURI(cfg, callback) {\n  const up = new Upload(cfg);\n\n  if (!callback) {\n    return up.createURI();\n  }\n\n  up.createURI().then(r => callback(null, r), callback);\n}\n\nexports.createURI = createURI;","map":{"version":3,"sources":["/Users/jaimeojeda/Documents/firebase/push_app/node_modules/@google-cloud/storage/build/src/gcs-resumable-upload/index.js"],"names":["Object","defineProperty","exports","value","createURI","upload","Upload","PROTOCOL_REGEX","abort_controller_1","require","ConfigStore","crypto_1","extend","gaxios","google_auth_library_1","Pumpify","stream_1","streamEvents","retry","NOT_FOUND_STATUS_CODE","TERMINATED_UPLOAD_STATUS_CODE","RESUMABLE_INCOMPLETE_STATUS_CODE","DEFAULT_API_ENDPOINT_REGEX","constructor","cfg","numBytesWritten","numRetries","upstreamChunkBuffer","Buffer","alloc","chunkBufferEncoding","undefined","numChunksReadInRequest","lastChunkSent","upstreamEnded","upstream","Duplex","read","once","push","write","writeToChunkBuffer","bind","bucket","file","Error","authConfig","scopes","authClient","GoogleAuth","apiEndpoint","sanitizeEndpoint","test","baseURI","cacheKeyElements","generation","cacheKey","join","customRequestOptions","kmsKeyName","metadata","offset","origin","params","userProject","chunkSize","retryOptions","key","base64Key","from","toString","encryption","hash","createHash","update","digest","predefinedAcl","private","public","configPath","configStore","autoRetry","uriProvidedManually","uri","get","maxRetries","timeOfFirstRequest","Date","now","contentLength","Number","NaN","isNaN","on","setPipeline","PassThrough","continueUploading","err","destroy","set","startUploading","chunk","encoding","readCallback","concat","process","nextTick","emit","unshiftChunkBuffer","pullFromChunkBuffer","limit","slice","waitForNextChunk","willBeMoreChunks","Promise","resolve","byteLength","wroteToChunkBufferCallback","removeListeners","upstreamFinishedCallback","length","removeListener","upstreamIterator","Infinity","oneChunkMode","completeChunk","callback","createURIAsync","then","r","reqOpts","method","url","assign","name","uploadType","data","headers","contentType","ifGenerationMatch","Origin","bail","_a","_b","_c","res","makeRequest","location","e","apiError","code","response","status","statusText","message","errors","reason","retryableErrorFn","retries","factor","retryDelayMultiplier","maxTimeout","maxRetryDelay","maxRetryTime","totalTimeout","getAndSetOffset","multiChunkMode","responseReceived","isSameObject","ensureUploadingSameObject","RangeError","fastForwardBytes","_chunk","expectedUploadSize","Math","min","upstreamQueue","requestStream","Readable","result","next","bytesWritten","done","endingByte","body","resp","makeRequestStream","responseHandler","error","shouldContinueWithNextMultiChunkRequest","range","split","missingBytes","dataToPrependForResending","isSuccessfulResponse","size","deleteConfig","upstreamChunk","cachedFirstChunk","firstChunk","valueOf","nextChunk","compare","restart","opts","validateStatus","combinedReqOpts","request","controller","default","errorCallback","abort","signal","successfulRequest","onResponse","prop","store","props","delete","attemptDelayedRetry","retryDelay","getRetryDelay","setTimeout","randomMs","round","random","waitTime","pow","maxAllowableDelayMs","maxRetryDelayMs","replace","up"],"mappings":"AAAA,a,CACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,SAAR,GAAoBF,OAAO,CAACG,MAAR,GAAiBH,OAAO,CAACI,MAAR,GAAiBJ,OAAO,CAACK,cAAR,GAAyB,KAAK,CAApF;;AACA,MAAMC,kBAAkB,GAAGC,OAAO,CAAC,kBAAD,CAAlC;;AACA,MAAMC,WAAW,GAAGD,OAAO,CAAC,aAAD,CAA3B;;AACA,MAAME,QAAQ,GAAGF,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAMG,MAAM,GAAGH,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAMI,MAAM,GAAGJ,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAMK,qBAAqB,GAAGL,OAAO,CAAC,qBAAD,CAArC;;AACA,MAAMM,OAAO,GAAGN,OAAO,CAAC,SAAD,CAAvB;;AACA,MAAMO,QAAQ,GAAGP,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAMQ,YAAY,GAAGR,OAAO,CAAC,eAAD,CAA5B;;AACA,MAAMS,KAAK,GAAGT,OAAO,CAAC,aAAD,CAArB;;AACA,MAAMU,qBAAqB,GAAG,GAA9B;AACA,MAAMC,6BAA6B,GAAG,GAAtC;AACA,MAAMC,gCAAgC,GAAG,GAAzC;AACA,MAAMC,0BAA0B,GAAG,qBAAnC;AACApB,OAAO,CAACK,cAAR,GAAyB,aAAzB;;AACA,MAAMD,MAAN,SAAqBS,OAArB,CAA6B;AACzBQ,EAAAA,WAAW,CAACC,GAAD,EAAM;AACb;AACA,SAAKC,eAAL,GAAuB,CAAvB;AACA,SAAKC,UAAL,GAAkB,CAAlB;AACA,SAAKC,mBAAL,GAA2BC,MAAM,CAACC,KAAP,CAAa,CAAb,CAA3B;AACA,SAAKC,mBAAL,GAA2BC,SAA3B;AACA,SAAKC,sBAAL,GAA8B,CAA9B;AACA;AACR;AACA;AACA;AACA;;AACQ,SAAKC,aAAL,GAAqBL,MAAM,CAACC,KAAP,CAAa,CAAb,CAArB;AACA,SAAKK,aAAL,GAAqB,KAArB;AACA;;AACA,SAAKC,QAAL,GAAgB,IAAInB,QAAQ,CAACoB,MAAb,CAAoB;AAChCC,MAAAA,IAAI,EAAE,YAAY;AACd,aAAKC,IAAL,CAAU,eAAV,EAA2B,MAAM;AAC7B;AACA,eAAKH,QAAL,CAAcI,IAAd,CAAmB,IAAnB;AACH,SAHD;AAIH,OAN+B;AAOhCC,MAAAA,KAAK,EAAE,KAAKC,kBAAL,CAAwBC,IAAxB,CAA6B,IAA7B;AAPyB,KAApB,CAAhB;AASAzB,IAAAA,YAAY,CAAC,IAAD,CAAZ;AACAO,IAAAA,GAAG,GAAGA,GAAG,IAAI,EAAb;;AACA,QAAI,CAACA,GAAG,CAACmB,MAAL,IAAe,CAACnB,GAAG,CAACoB,IAAxB,EAA8B;AAC1B,YAAM,IAAIC,KAAJ,CAAU,qCAAV,CAAN;AACH;;AACDrB,IAAAA,GAAG,CAACsB,UAAJ,GAAiBtB,GAAG,CAACsB,UAAJ,IAAkB,EAAnC;AACAtB,IAAAA,GAAG,CAACsB,UAAJ,CAAeC,MAAf,GAAwB,CACpB,yDADoB,CAAxB;AAGA,SAAKC,UAAL,GAAkBxB,GAAG,CAACwB,UAAJ,IAAkB,IAAIlC,qBAAqB,CAACmC,UAA1B,CAAqCzB,GAAG,CAACsB,UAAzC,CAApC;AACA,SAAKI,WAAL,GAAmB,gCAAnB;;AACA,QAAI1B,GAAG,CAAC0B,WAAR,EAAqB;AACjB,WAAKA,WAAL,GAAmB,KAAKC,gBAAL,CAAsB3B,GAAG,CAAC0B,WAA1B,CAAnB;;AACA,UAAI,CAAC5B,0BAA0B,CAAC8B,IAA3B,CAAgC5B,GAAG,CAAC0B,WAApC,CAAL,EAAuD;AACnD,aAAKF,UAAL,GAAkBnC,MAAlB;AACH;AACJ;;AACD,SAAKwC,OAAL,GAAgB,GAAE,KAAKH,WAAY,sBAAnC;AACA,SAAKP,MAAL,GAAcnB,GAAG,CAACmB,MAAlB;AACA,UAAMW,gBAAgB,GAAG,CAAC9B,GAAG,CAACmB,MAAL,EAAanB,GAAG,CAACoB,IAAjB,CAAzB;;AACA,QAAI,OAAOpB,GAAG,CAAC+B,UAAX,KAA0B,QAA9B,EAAwC;AACpCD,MAAAA,gBAAgB,CAACf,IAAjB,CAAuB,GAAEf,GAAG,CAAC+B,UAAW,EAAxC;AACH;;AACD,SAAKC,QAAL,GAAgBF,gBAAgB,CAACG,IAAjB,CAAsB,GAAtB,CAAhB;AACA,SAAKC,oBAAL,GAA4BlC,GAAG,CAACkC,oBAAJ,IAA4B,EAAxD;AACA,SAAKd,IAAL,GAAYpB,GAAG,CAACoB,IAAhB;AACA,SAAKW,UAAL,GAAkB/B,GAAG,CAAC+B,UAAtB;AACA,SAAKI,UAAL,GAAkBnC,GAAG,CAACmC,UAAtB;AACA,SAAKC,QAAL,GAAgBpC,GAAG,CAACoC,QAAJ,IAAgB,EAAhC;AACA,SAAKC,MAAL,GAAcrC,GAAG,CAACqC,MAAlB;AACA,SAAKC,MAAL,GAActC,GAAG,CAACsC,MAAlB;AACA,SAAKC,MAAL,GAAcvC,GAAG,CAACuC,MAAJ,IAAc,EAA5B;AACA,SAAKC,WAAL,GAAmBxC,GAAG,CAACwC,WAAvB;AACA,SAAKC,SAAL,GAAiBzC,GAAG,CAACyC,SAArB;AACA,SAAKC,YAAL,GAAoB1C,GAAG,CAAC0C,YAAxB;;AACA,QAAI1C,GAAG,CAAC2C,GAAR,EAAa;AACT;AACZ;AACA;AACA;AACA;AACY,YAAMC,SAAS,GAAGxC,MAAM,CAACyC,IAAP,CAAY7C,GAAG,CAAC2C,GAAhB,EAAqBG,QAArB,CAA8B,QAA9B,CAAlB;AACA,WAAKC,UAAL,GAAkB;AACdJ,QAAAA,GAAG,EAAEC,SADS;AAEdI,QAAAA,IAAI,EAAE7D,QAAQ,CAAC8D,UAAT,CAAoB,QAApB,EAA8BC,MAA9B,CAAqClD,GAAG,CAAC2C,GAAzC,EAA8CQ,MAA9C,CAAqD,QAArD;AAFQ,OAAlB;AAIH;;AACD,SAAKC,aAAL,GAAqBpD,GAAG,CAACoD,aAAzB;AACA,QAAIpD,GAAG,CAACqD,OAAR,EACI,KAAKD,aAAL,GAAqB,SAArB;AACJ,QAAIpD,GAAG,CAACsD,MAAR,EACI,KAAKF,aAAL,GAAqB,YAArB;AACJ,UAAMG,UAAU,GAAGvD,GAAG,CAACuD,UAAvB;AACA,SAAKC,WAAL,GAAmB,IAAItE,WAAJ,CAAgB,sBAAhB,EAAwC,IAAxC,EAA8C;AAC7DqE,MAAAA;AAD6D,KAA9C,CAAnB;AAGA,UAAME,SAAS,GAAGzD,GAAG,CAAC0C,YAAJ,CAAiBe,SAAnC;AACA,SAAKC,mBAAL,GAA2B,CAAC,CAAC1D,GAAG,CAAC2D,GAAjC;AACA,SAAKA,GAAL,GAAW3D,GAAG,CAAC2D,GAAJ,IAAW,KAAKC,GAAL,CAAS,KAAT,CAAtB;AACA,SAAK3D,eAAL,GAAuB,CAAvB;AACA,SAAKC,UAAL,GAAkB,CAAlB,CApFa,CAoFQ;;AACrB,QAAI,CAACuD,SAAL,EAAgB;AACZzD,MAAAA,GAAG,CAAC0C,YAAJ,CAAiBmB,UAAjB,GAA8B,CAA9B;AACH;;AACD,SAAKC,kBAAL,GAA0BC,IAAI,CAACC,GAAL,EAA1B;AACA,UAAMC,aAAa,GAAGjE,GAAG,CAACoC,QAAJ,GAChB8B,MAAM,CAAClE,GAAG,CAACoC,QAAJ,CAAa6B,aAAd,CADU,GAEhBE,GAFN;AAGA,SAAKF,aAAL,GAAqBG,KAAK,CAACH,aAAD,CAAL,GAAuB,GAAvB,GAA6BA,aAAlD;AACA,SAAKtD,QAAL,CAAc0D,EAAd,CAAiB,KAAjB,EAAwB,MAAM;AAC1B,WAAK3D,aAAL,GAAqB,IAArB;AACH,KAFD;AAGA,SAAK2D,EAAL,CAAQ,WAAR,EAAqB,MAAM;AACvB,WAAK3D,aAAL,GAAqB,IAArB;AACH,KAFD;AAGA,SAAKI,IAAL,CAAU,SAAV,EAAqB,MAAM;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,WAAKwD,WAAL,CAAiB,KAAK3D,QAAtB,EAAgC,IAAInB,QAAQ,CAAC+E,WAAb,EAAhC;;AACA,UAAI,KAAKZ,GAAT,EAAc;AACV,aAAKa,iBAAL;AACH,OAFD,MAGK;AACD,aAAK5F,SAAL,CAAe,CAAC6F,GAAD,EAAMd,GAAN,KAAc;AACzB,cAAIc,GAAJ,EAAS;AACL,mBAAO,KAAKC,OAAL,CAAaD,GAAb,CAAP;AACH;;AACD,eAAKE,GAAL,CAAS;AAAEhB,YAAAA;AAAF,WAAT;AACA,eAAKiB,cAAL;AACA;AACH,SAPD;AAQH;AACJ,KArBD;AAsBH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACI3D,EAAAA,kBAAkB,CAAC4D,KAAD,EAAQC,QAAR,EAAkBC,YAAlB,EAAgC;AAC9C,SAAK5E,mBAAL,GAA2BC,MAAM,CAAC4E,MAAP,CAAc,CACrC,KAAK7E,mBADgC,EAErC,OAAO0E,KAAP,KAAiB,QAAjB,GAA4BzE,MAAM,CAACyC,IAAP,CAAYgC,KAAZ,EAAmBC,QAAnB,CAA5B,GAA2DD,KAFtB,CAAd,CAA3B;AAIA,SAAKvE,mBAAL,GAA2BwE,QAA3B;AACA,SAAKhE,IAAL,CAAU,qBAAV,EAAiCiE,YAAjC;AACAE,IAAAA,OAAO,CAACC,QAAR,CAAiB,MAAM,KAAKC,IAAL,CAAU,oBAAV,CAAvB;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACIC,EAAAA,kBAAkB,CAACP,KAAD,EAAQ;AACtB,SAAK1E,mBAAL,GAA2BC,MAAM,CAAC4E,MAAP,CAAc,CAACH,KAAD,EAAQ,KAAK1E,mBAAb,CAAd,CAA3B;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACIkF,EAAAA,mBAAmB,CAACC,KAAD,EAAQ;AACvB,UAAMT,KAAK,GAAG,KAAK1E,mBAAL,CAAyBoF,KAAzB,CAA+B,CAA/B,EAAkCD,KAAlC,CAAd;AACA,SAAKnF,mBAAL,GAA2B,KAAKA,mBAAL,CAAyBoF,KAAzB,CAA+BD,KAA/B,CAA3B,CAFuB,CAGvB;AACA;;AACAL,IAAAA,OAAO,CAACC,QAAR,CAAiB,MAAM,KAAKC,IAAL,CAAU,qBAAV,CAAvB;AACA,WAAON,KAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AAC0B,QAAhBW,gBAAgB,GAAG;AACrB,UAAMC,gBAAgB,GAAG,MAAM,IAAIC,OAAJ,CAAYC,OAAO,IAAI;AAClD;AACA,UAAI,KAAKxF,mBAAL,CAAyByF,UAA7B,EAAyC;AACrC,eAAOD,OAAO,CAAC,IAAD,CAAd;AACH,OAJiD,CAKlD;;;AACA,UAAI,KAAKjF,aAAT,EAAwB;AACpB,eAAOiF,OAAO,CAAC,KAAD,CAAd;AACH,OARiD,CASlD;AACA;;;AACA,YAAME,0BAA0B,GAAG,MAAM;AACrCC,QAAAA,eAAe;AACf,eAAOH,OAAO,CAAC,IAAD,CAAd;AACH,OAHD;;AAIA,YAAMI,wBAAwB,GAAG,MAAM;AACnCD,QAAAA,eAAe,GADoB,CAEnC;;AACA,YAAI,KAAK3F,mBAAL,CAAyB6F,MAA7B,EACI,OAAOL,OAAO,CAAC,IAAD,CAAd;AACJ,eAAOA,OAAO,CAAC,KAAD,CAAd;AACH,OAND,CAfkD,CAsBlD;AACA;AACA;AACA;AACA;;;AACA,YAAMG,eAAe,GAAG,MAAM;AAC1B,aAAKG,cAAL,CAAoB,oBAApB,EAA0CJ,0BAA1C;AACA,aAAKlF,QAAL,CAAcsF,cAAd,CAA6B,QAA7B,EAAuCF,wBAAvC;AACA,aAAKE,cAAL,CAAoB,WAApB,EAAiCF,wBAAjC;AACH,OAJD,CA3BkD,CAgClD;;;AACA,WAAKjF,IAAL,CAAU,oBAAV,EAAgC+E,0BAAhC,EAjCkD,CAkClD;;AACA,WAAKlF,QAAL,CAAcG,IAAd,CAAmB,QAAnB,EAA6BiF,wBAA7B;AACA,WAAKjF,IAAL,CAAU,WAAV,EAAuBiF,wBAAvB;AACH,KArC8B,CAA/B;AAsCA,WAAON,gBAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AAC2B,SAAhBS,gBAAgB,GAAiC;AAAA,QAAhCZ,KAAgC,uEAAxBa,QAAwB;AAAA,QAAdC,YAAc;AACpD,QAAIC,aAAa,GAAGjG,MAAM,CAACC,KAAP,CAAa,CAAb,CAApB,CADoD,CAEpD;;AACA,WAAOiF,KAAK,KAAK,MAAM,KAAKE,gBAAL,EAAX,CAAZ,EAAiD;AAC7C;AACA,YAAMX,KAAK,GAAG,KAAKQ,mBAAL,CAAyBC,KAAzB,CAAd;AACAA,MAAAA,KAAK,IAAIT,KAAK,CAACe,UAAf;;AACA,UAAIQ,YAAJ,EAAkB;AACd;AACAC,QAAAA,aAAa,GAAGjG,MAAM,CAAC4E,MAAP,CAAc,CAACqB,aAAD,EAAgBxB,KAAhB,CAAd,CAAhB;AACH,OAHD,MAIK;AACD;AACA,cAAM;AACFA,UAAAA,KADE;AAEFC,UAAAA,QAAQ,EAAE,KAAKxE;AAFb,SAAN;AAIH;AACJ;;AACD,QAAI8F,YAAJ,EAAkB;AACd,YAAM;AACFvB,QAAAA,KAAK,EAAEwB,aADL;AAEFvB,QAAAA,QAAQ,EAAE,KAAKxE;AAFb,OAAN;AAIH;AACJ;;AACD1B,EAAAA,SAAS,CAAC0H,QAAD,EAAW;AAChB,QAAI,CAACA,QAAL,EAAe;AACX,aAAO,KAAKC,cAAL,EAAP;AACH;;AACD,SAAKA,cAAL,GAAsBC,IAAtB,CAA2BC,CAAC,IAAIH,QAAQ,CAAC,IAAD,EAAOG,CAAP,CAAxC,EAAmDH,QAAnD;AACH;;AACmB,QAAdC,cAAc,GAAG;AACnB,UAAMnE,QAAQ,GAAG,KAAKA,QAAtB;AACA,UAAMsE,OAAO,GAAG;AACZC,MAAAA,MAAM,EAAE,MADI;AAEZC,MAAAA,GAAG,EAAE,CAAC,KAAK/E,OAAN,EAAe,KAAKV,MAApB,EAA4B,GAA5B,EAAiCc,IAAjC,CAAsC,GAAtC,CAFO;AAGZM,MAAAA,MAAM,EAAE/D,MAAM,CAACqI,MAAP,CAAc;AAClBC,QAAAA,IAAI,EAAE,KAAK1F,IADO;AAElB2F,QAAAA,UAAU,EAAE;AAFM,OAAd,EAGL,KAAKxE,MAHA,CAHI;AAOZyE,MAAAA,IAAI,EAAE5E,QAPM;AAQZ6E,MAAAA,OAAO,EAAE;AARG,KAAhB;;AAUA,QAAI7E,QAAQ,CAAC6B,aAAb,EAA4B;AACxByC,MAAAA,OAAO,CAACO,OAAR,CAAgB,yBAAhB,IACI7E,QAAQ,CAAC6B,aAAT,CAAuBnB,QAAvB,EADJ;AAEH;;AACD,QAAIV,QAAQ,CAAC8E,WAAb,EAA0B;AACtBR,MAAAA,OAAO,CAACO,OAAR,CAAgB,uBAAhB,IAA2C7E,QAAQ,CAAC8E,WAApD;AACH;;AACD,QAAI,OAAO,KAAKnF,UAAZ,KAA2B,WAA/B,EAA4C;AACxC2E,MAAAA,OAAO,CAACnE,MAAR,CAAe4E,iBAAf,GAAmC,KAAKpF,UAAxC;AACH;;AACD,QAAI,KAAKI,UAAT,EAAqB;AACjBuE,MAAAA,OAAO,CAACnE,MAAR,CAAeJ,UAAf,GAA4B,KAAKA,UAAjC;AACH;;AACD,QAAI,KAAKiB,aAAT,EAAwB;AACpBsD,MAAAA,OAAO,CAACnE,MAAR,CAAea,aAAf,GAA+B,KAAKA,aAApC;AACH;;AACD,QAAI,KAAKd,MAAT,EAAiB;AACboE,MAAAA,OAAO,CAACO,OAAR,CAAgBG,MAAhB,GAAyB,KAAK9E,MAA9B;AACH;;AACD,UAAMqB,GAAG,GAAG,MAAMjE,KAAK,CAAC,MAAO2H,IAAP,IAAgB;AACpC,UAAIC,EAAJ,EAAQC,EAAR,EAAYC,EAAZ;;AACA,UAAI;AACA,cAAMC,GAAG,GAAG,MAAM,KAAKC,WAAL,CAAiBhB,OAAjB,CAAlB;AACA,eAAOe,GAAG,CAACR,OAAJ,CAAYU,QAAnB;AACH,OAHD,CAIA,OAAOlD,GAAP,EAAY;AACR,cAAMmD,CAAC,GAAGnD,GAAV;AACA,cAAMoD,QAAQ,GAAG;AACbC,UAAAA,IAAI,EAAE,CAACR,EAAE,GAAGM,CAAC,CAACG,QAAR,MAAsB,IAAtB,IAA8BT,EAAE,KAAK,KAAK,CAA1C,GAA8C,KAAK,CAAnD,GAAuDA,EAAE,CAACU,MADnD;AAEblB,UAAAA,IAAI,EAAE,CAACS,EAAE,GAAGK,CAAC,CAACG,QAAR,MAAsB,IAAtB,IAA8BR,EAAE,KAAK,KAAK,CAA1C,GAA8C,KAAK,CAAnD,GAAuDA,EAAE,CAACU,UAFnD;AAGbC,UAAAA,OAAO,EAAE,CAACV,EAAE,GAAGI,CAAC,CAACG,QAAR,MAAsB,IAAtB,IAA8BP,EAAE,KAAK,KAAK,CAA1C,GAA8C,KAAK,CAAnD,GAAuDA,EAAE,CAACS,UAHtD;AAIbE,UAAAA,MAAM,EAAE,CACJ;AACIC,YAAAA,MAAM,EAAER,CAAC,CAACE;AADd,WADI;AAJK,SAAjB;;AAUA,YAAI,KAAKpF,YAAL,CAAkBmB,UAAlB,GAA+B,CAA/B,IACA,KAAKnB,YAAL,CAAkB2F,gBAAlB,CAAmCR,QAAnC,CADJ,EACkD;AAC9C,gBAAMD,CAAN;AACH,SAHD,MAIK;AACD,iBAAOP,IAAI,CAACO,CAAD,CAAX;AACH;AACJ;AACJ,KA1BsB,EA0BpB;AACCU,MAAAA,OAAO,EAAE,KAAK5F,YAAL,CAAkBmB,UAD5B;AAEC0E,MAAAA,MAAM,EAAE,KAAK7F,YAAL,CAAkB8F,oBAF3B;AAGCC,MAAAA,UAAU,EAAE,KAAK/F,YAAL,CAAkBgG,aAAlB,GAAkC,IAH/C;AAICC,MAAAA,YAAY,EAAE,KAAKjG,YAAL,CAAkBkG,YAAlB,GAAiC;AAJhD,KA1BoB,CAAvB;AAgCA,SAAKjF,GAAL,GAAWA,GAAX;AACA,SAAKtB,MAAL,GAAc,CAAd;AACA,WAAOsB,GAAP;AACH;;AACsB,QAAjBa,iBAAiB,GAAG;AACtB,QAAI,OAAO,KAAKnC,MAAZ,KAAuB,QAA3B,EAAqC;AACjC,WAAKuC,cAAL;AACA;AACH;;AACD,UAAM,KAAKiE,eAAL,EAAN;AACA,SAAKjE,cAAL;AACH;;AACmB,QAAdA,cAAc,GAAG;AACnB,UAAMkE,cAAc,GAAG,CAAC,CAAC,KAAKrG,SAA9B;AACA,QAAIsG,gBAAgB,GAAG,KAAvB;AACA,SAAKvI,sBAAL,GAA8B,CAA9B;;AACA,QAAI,CAAC,KAAK6B,MAAV,EAAkB;AACd,WAAKA,MAAL,GAAc,CAAd;AACH,KANkB,CAOnB;;;AACA,QAAI,KAAKpC,eAAL,KAAyB,CAA7B,EAAgC;AAC5B,YAAM+I,YAAY,GAAG,MAAM,KAAKC,yBAAL,EAA3B;;AACA,UAAI,CAACD,YAAL,EAAmB;AACf;AACA;AACH;AACJ,KAdkB,CAenB;;;AACA,QAAI,KAAK3G,MAAL,GAAc,KAAKpC,eAAvB,EAAwC;AACpC,WAAKkF,IAAL,CAAU,OAAV,EAAmB,IAAI+D,UAAJ,CAAe,sDAAf,CAAnB;AACA;AACH,KAnBkB,CAoBnB;;;AACA,QAAI,KAAKjJ,eAAL,GAAuB,KAAKoC,MAAhC,EAAwC;AACpC;AACA;AACA,YAAM8G,gBAAgB,GAAG,KAAK9G,MAAL,GAAc,KAAKpC,eAA5C;;AACA,iBAAW,MAAMmJ,MAAjB,IAA2B,KAAKlD,gBAAL,CAAsBiD,gBAAtB,CAA3B,EAAoE;AAChEC,QAAAA,MAAM,CAD0D,CACxD;AACX;;AACD,WAAKnJ,eAAL,GAAuB,KAAKoC,MAA5B;AACH;;AACD,QAAIgH,kBAAkB,GAAG9I,SAAzB,CA9BmB,CA+BnB;;AACA,QAAI,OAAO,KAAK0D,aAAZ,KAA8B,QAAlC,EAA4C;AACxCoF,MAAAA,kBAAkB,GAAG,KAAKpF,aAAL,GAAqB,KAAKhE,eAA/C;AACH,KAlCkB,CAmCnB;AACA;AACA;;;AACA,QAAI,KAAKwC,SAAT,EAAoB;AAChB4G,MAAAA,kBAAkB,GAAGA,kBAAkB,GACjCC,IAAI,CAACC,GAAL,CAAS,KAAK9G,SAAd,EAAyB4G,kBAAzB,CADiC,GAEjC,KAAK5G,SAFX;AAGH,KA1CkB,CA2CnB;;;AACA,UAAM+G,aAAa,GAAG,KAAKtD,gBAAL,CAAsBmD,kBAAtB,EAA0CP,cAA1C,CAAyD;AAAzD,KAAtB,CA5CmB,CA8CnB;AACA;;AACA,UAAMW,aAAa,GAAG,IAAIjK,QAAQ,CAACkK,QAAb,CAAsB;AACxC7I,MAAAA,IAAI,EAAE,YAAY;AACd;AACA,YAAIkI,gBAAJ,EACIU,aAAa,CAAC1I,IAAd,CAAmB,IAAnB;AACJ,cAAM4I,MAAM,GAAG,MAAMH,aAAa,CAACI,IAAd,EAArB;;AACA,YAAID,MAAM,CAAChL,KAAX,EAAkB;AACd,eAAK6B,sBAAL;AACA,eAAKC,aAAL,GAAqBkJ,MAAM,CAAChL,KAAP,CAAakG,KAAlC;AACA,eAAK5E,eAAL,IAAwB0J,MAAM,CAAChL,KAAP,CAAakG,KAAb,CAAmBe,UAA3C;AACA,eAAKT,IAAL,CAAU,UAAV,EAAsB;AAClB0E,YAAAA,YAAY,EAAE,KAAK5J,eADD;AAElBgE,YAAAA,aAAa,EAAE,KAAKA;AAFF,WAAtB;AAIAwF,UAAAA,aAAa,CAAC1I,IAAd,CAAmB4I,MAAM,CAAChL,KAAP,CAAakG,KAAhC,EAAuC8E,MAAM,CAAChL,KAAP,CAAamG,QAApD;AACH;;AACD,YAAI6E,MAAM,CAACG,IAAX,EAAiB;AACbL,UAAAA,aAAa,CAAC1I,IAAd,CAAmB,IAAnB;AACH;AACJ;AAnBuC,KAAtB,CAAtB;AAqBA,QAAIkG,OAAO,GAAG,EAAd,CArEmB,CAsEnB;;AACA,QAAI6B,cAAc,IAAIO,kBAAtB,EAA0C;AACtC;AACA,YAAMU,UAAU,GAAGV,kBAAkB,GAAG,KAAKpJ,eAA1B,GAA4C,CAA/D;AACAgH,MAAAA,OAAO,GAAG;AACN,0BAAkBoC,kBADZ;AAEN,yBAAkB,SAAQ,KAAKhH,MAAO,IAAG0H,UAAW,IAAG,KAAK9F,aAAc;AAFpE,OAAV;AAIH,KAPD,MAQK;AACDgD,MAAAA,OAAO,GAAG;AACN,yBAAkB,SAAQ,KAAK5E,MAAO,MAAK,KAAK4B,aAAc;AADxD,OAAV;AAGH;;AACD,UAAMyC,OAAO,GAAG;AACZC,MAAAA,MAAM,EAAE,KADI;AAEZC,MAAAA,GAAG,EAAE,KAAKjD,GAFE;AAGZsD,MAAAA,OAHY;AAIZ+C,MAAAA,IAAI,EAAEP;AAJM,KAAhB;;AAMA,QAAI;AACA,YAAMQ,IAAI,GAAG,MAAM,KAAKC,iBAAL,CAAuBxD,OAAvB,CAAnB;;AACA,UAAIuD,IAAJ,EAAU;AACNlB,QAAAA,gBAAgB,GAAG,IAAnB;AACA,aAAKoB,eAAL,CAAqBF,IAArB;AACH;AACJ,KAND,CAOA,OAAOxF,GAAP,EAAY;AACR,YAAMmD,CAAC,GAAGnD,GAAV;AACA,WAAKC,OAAL,CAAakD,CAAb;AACH;AACJ,GAtawB,CAuazB;AACA;;;AACAuC,EAAAA,eAAe,CAACF,IAAD,EAAO;AAClB,QAAIA,IAAI,CAACjD,IAAL,CAAUoD,KAAd,EAAqB;AACjB,WAAK1F,OAAL,CAAauF,IAAI,CAACjD,IAAL,CAAUoD,KAAvB;AACA;AACH;;AACD,UAAMC,uCAAuC,GAAG,KAAK5H,SAAL,IAC5CwH,IAAI,CAACjC,MAAL,KAAgBnI,gCAD4B,IAE5CoK,IAAI,CAAChD,OAAL,CAAaqD,KAFjB;;AAGA,QAAID,uCAAJ,EAA6C;AACzC;AACA;AACA;AACA,YAAMC,KAAK,GAAGL,IAAI,CAAChD,OAAL,CAAaqD,KAA3B;AACA,WAAKjI,MAAL,GAAc6B,MAAM,CAACoG,KAAK,CAACC,KAAN,CAAY,GAAZ,EAAiB,CAAjB,CAAD,CAAN,GAA8B,CAA5C,CALyC,CAMzC;AACA;;AACA,YAAMC,YAAY,GAAG,KAAKvK,eAAL,GAAuB,KAAKoC,MAAjD;;AACA,UAAImI,YAAJ,EAAkB;AACd,cAAMC,yBAAyB,GAAG,KAAKhK,aAAL,CAAmB8E,KAAnB,CAAyB,CAACiF,YAA1B,CAAlC,CADc,CAEd;AACA;AACA;;AACA,aAAKpF,kBAAL,CAAwBqF,yBAAxB;AACA,aAAKxK,eAAL,IAAwBuK,YAAxB;AACA,aAAK/J,aAAL,GAAqBL,MAAM,CAACC,KAAP,CAAa,CAAb,CAArB;AACH,OAjBwC,CAkBzC;;;AACA,WAAKmE,iBAAL;AACH,KApBD,MAqBK,IAAI,CAAC,KAAKkG,oBAAL,CAA0BT,IAAI,CAACjC,MAA/B,CAAL,EAA6C;AAC9C,YAAMvD,GAAG,GAAG;AACRqD,QAAAA,IAAI,EAAEmC,IAAI,CAACjC,MADH;AAERlB,QAAAA,IAAI,EAAE,eAFE;AAGRoB,QAAAA,OAAO,EAAE;AAHD,OAAZ;AAKA,WAAKxD,OAAL,CAAaD,GAAb;AACH,KAPI,MAQA;AACD;AACA,WAAKhE,aAAL,GAAqBL,MAAM,CAACC,KAAP,CAAa,CAAb,CAArB;;AACA,UAAI4J,IAAI,IAAIA,IAAI,CAACjD,IAAjB,EAAuB;AACnBiD,QAAAA,IAAI,CAACjD,IAAL,CAAU2D,IAAV,GAAiBzG,MAAM,CAAC+F,IAAI,CAACjD,IAAL,CAAU2D,IAAX,CAAvB;AACH;;AACD,WAAKxF,IAAL,CAAU,UAAV,EAAsB8E,IAAI,CAACjD,IAA3B;AACA,WAAK4D,YAAL,GAPC,CAQD;AACA;;AACA,WAAKzF,IAAL,CAAU,eAAV;AACH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACmC,QAAzB8D,yBAAyB,GAAG;AAC9B;AACA,UAAMO,aAAa,GAAG,KAAKtD,gBAAL,CAAsB,EAAtB,EAA0B,IAA1B,CAA+B;AAA/B,KAAtB;AAEA,UAAM2E,aAAa,GAAG,MAAMrB,aAAa,CAACI,IAAd,EAA5B;AACA,UAAM/E,KAAK,GAAGgG,aAAa,CAAClM,KAAd,GACRkM,aAAa,CAAClM,KAAd,CAAoBkG,KADZ,GAERzE,MAAM,CAACC,KAAP,CAAa,CAAb,CAFN,CAL8B,CAQ9B;AACA;;AACA,SAAK+E,kBAAL,CAAwBP,KAAxB;AACA,QAAIiG,gBAAgB,GAAG,KAAKlH,GAAL,CAAS,YAAT,CAAvB;AACA,UAAMmH,UAAU,GAAGlG,KAAK,CAACmG,OAAN,EAAnB;;AACA,QAAI,CAACF,gBAAL,EAAuB;AACnB;AACA,WAAKnG,GAAL,CAAS;AAAEhB,QAAAA,GAAG,EAAE,KAAKA,GAAZ;AAAiBoH,QAAAA;AAAjB,OAAT;AACH,KAHD,MAIK;AACD;AACAD,MAAAA,gBAAgB,GAAG1K,MAAM,CAACyC,IAAP,CAAYiI,gBAAZ,CAAnB;AACA,YAAMG,SAAS,GAAG7K,MAAM,CAACyC,IAAP,CAAYkI,UAAZ,CAAlB;;AACA,UAAI3K,MAAM,CAAC8K,OAAP,CAAeJ,gBAAf,EAAiCG,SAAjC,MAAgD,CAApD,EAAuD;AACnD;AACA,aAAKE,OAAL;AACA,eAAO,KAAP;AACH;AACJ;;AACD,WAAO,IAAP;AACH;;AACoB,QAAftC,eAAe,GAAG;AACpB,UAAMuC,IAAI,GAAG;AACTzE,MAAAA,MAAM,EAAE,KADC;AAETC,MAAAA,GAAG,EAAE,KAAKjD,GAFD;AAGTsD,MAAAA,OAAO,EAAE;AAAE,0BAAkB,CAApB;AAAuB,yBAAiB;AAAxC;AAHA,KAAb;;AAKA,QAAI;AACA,YAAMgD,IAAI,GAAG,MAAM,KAAKvC,WAAL,CAAiB0D,IAAjB,CAAnB;;AACA,UAAInB,IAAI,CAACjC,MAAL,KAAgBnI,gCAApB,EAAsD;AAClD,YAAIoK,IAAI,CAAChD,OAAL,CAAaqD,KAAjB,EAAwB;AACpB,gBAAMA,KAAK,GAAGL,IAAI,CAAChD,OAAL,CAAaqD,KAA3B;AACA,eAAKjI,MAAL,GAAc6B,MAAM,CAACoG,KAAK,CAACC,KAAN,CAAY,GAAZ,EAAiB,CAAjB,CAAD,CAAN,GAA8B,CAA5C;AACA;AACH;AACJ;;AACD,WAAKlI,MAAL,GAAc,CAAd;AACH,KAVD,CAWA,OAAOuF,CAAP,EAAU;AACN,YAAMnD,GAAG,GAAGmD,CAAZ;AACA,YAAMqC,IAAI,GAAGxF,GAAG,CAACsD,QAAjB,CAFM,CAGN;AACA;AACA;AACA;;AACA,UAAIkC,IAAI,IACJA,IAAI,CAACjC,MAAL,KAAgBrI,qBADhB,IAEA,CAAC,KAAK+D,mBAFV,EAE+B;AAC3B,aAAKyH,OAAL;AACA;AACH,OAZK,CAaN;AACA;AACA;AACA;AACA;;;AACA,UAAIlB,IAAI,IAAIA,IAAI,CAACjC,MAAL,KAAgBpI,6BAA5B,EAA2D;AACvD,aAAKuL,OAAL;AACA;AACH;;AACD,WAAKzG,OAAL,CAAaD,GAAb;AACH;AACJ;;AACgB,QAAXiD,WAAW,CAAChB,OAAD,EAAU;AACvB,QAAI,KAAK3D,UAAT,EAAqB;AACjB2D,MAAAA,OAAO,CAACO,OAAR,GAAkBP,OAAO,CAACO,OAAR,IAAmB,EAArC;AACAP,MAAAA,OAAO,CAACO,OAAR,CAAgB,6BAAhB,IAAiD,QAAjD;AACAP,MAAAA,OAAO,CAACO,OAAR,CAAgB,uBAAhB,IAA2C,KAAKlE,UAAL,CAAgBJ,GAAhB,CAAoBG,QAApB,EAA3C;AACA4D,MAAAA,OAAO,CAACO,OAAR,CAAgB,8BAAhB,IACI,KAAKlE,UAAL,CAAgBC,IAAhB,CAAqBF,QAArB,EADJ;AAEH;;AACD,QAAI,KAAKN,WAAT,EAAsB;AAClBkE,MAAAA,OAAO,CAACnE,MAAR,GAAiBmE,OAAO,CAACnE,MAAR,IAAkB,EAAnC;AACAmE,MAAAA,OAAO,CAACnE,MAAR,CAAeC,WAAf,GAA6B,KAAKA,WAAlC;AACH,KAXsB,CAYvB;;;AACAkE,IAAAA,OAAO,CAAC2E,cAAR,GAA0BrD,MAAD,IAAY;AACjC,aAAQ,KAAK0C,oBAAL,CAA0B1C,MAA1B,KACJA,MAAM,KAAKnI,gCADf;AAEH,KAHD;;AAIA,UAAMyL,eAAe,GAAGlM,MAAM,CAAC,IAAD,EAAO,EAAP,EAAW,KAAK8C,oBAAhB,EAAsCwE,OAAtC,CAA9B;AACA,UAAMe,GAAG,GAAG,MAAM,KAAKjG,UAAL,CAAgB+J,OAAhB,CAAwBD,eAAxB,CAAlB;;AACA,QAAI7D,GAAG,CAACT,IAAJ,IAAYS,GAAG,CAACT,IAAJ,CAASoD,KAAzB,EAAgC;AAC5B,YAAM3C,GAAG,CAACT,IAAJ,CAASoD,KAAf;AACH;;AACD,WAAO3C,GAAP;AACH;;AACsB,QAAjByC,iBAAiB,CAACxD,OAAD,EAAU;AAC7B,UAAM8E,UAAU,GAAG,IAAIxM,kBAAkB,CAACyM,OAAvB,EAAnB;;AACA,UAAMC,aAAa,GAAG,MAAMF,UAAU,CAACG,KAAX,EAA5B;;AACA,SAAK7K,IAAL,CAAU,OAAV,EAAmB4K,aAAnB;;AACA,QAAI,KAAKlJ,WAAT,EAAsB;AAClBkE,MAAAA,OAAO,CAACnE,MAAR,GAAiBmE,OAAO,CAACnE,MAAR,IAAkB,EAAnC;AACAmE,MAAAA,OAAO,CAACnE,MAAR,CAAeC,WAAf,GAA6B,KAAKA,WAAlC;AACH;;AACDkE,IAAAA,OAAO,CAACkF,MAAR,GAAiBJ,UAAU,CAACI,MAA5B;;AACAlF,IAAAA,OAAO,CAAC2E,cAAR,GAAyB,MAAM,IAA/B;;AACA,UAAMC,eAAe,GAAGlM,MAAM,CAAC,IAAD,EAAO,EAAP,EAAW,KAAK8C,oBAAhB,EAAsCwE,OAAtC,CAA9B;AACA,UAAMe,GAAG,GAAG,MAAM,KAAKjG,UAAL,CAAgB+J,OAAhB,CAAwBD,eAAxB,CAAlB;AACA,UAAMO,iBAAiB,GAAG,KAAKC,UAAL,CAAgBrE,GAAhB,CAA1B;AACA,SAAKxB,cAAL,CAAoB,OAApB,EAA6ByF,aAA7B;AACA,WAAOG,iBAAiB,GAAGpE,GAAH,GAAS,IAAjC;AACH;;AACD0D,EAAAA,OAAO,GAAG;AACN,QAAI,KAAKlL,eAAT,EAA0B;AACtB,UAAIiI,OAAO,GAAG,6FAAd;AACAA,MAAAA,OAAO,IAAI,8CAAX;AACAA,MAAAA,OAAO,IAAI,yCAAX;AACA,WAAK/C,IAAL,CAAU,OAAV,EAAmB,IAAI+D,UAAJ,CAAehB,OAAf,CAAnB;AACA;AACH;;AACD,SAAKzH,aAAL,GAAqBL,MAAM,CAACC,KAAP,CAAa,CAAb,CAArB;AACA,SAAKuK,YAAL;AACA,SAAKhM,SAAL,CAAe,CAAC6F,GAAD,EAAMd,GAAN,KAAc;AACzB,UAAIc,GAAJ,EAAS;AACL,eAAO,KAAKC,OAAL,CAAaD,GAAb,CAAP;AACH;;AACD,WAAKE,GAAL,CAAS;AAAEhB,QAAAA;AAAF,OAAT;AACA,WAAKiB,cAAL;AACA;AACH,KAPD;AAQH;;AACDhB,EAAAA,GAAG,CAACmI,IAAD,EAAO;AACN,UAAMC,KAAK,GAAG,KAAKxI,WAAL,CAAiBI,GAAjB,CAAqB,KAAK5B,QAA1B,CAAd;AACA,WAAOgK,KAAK,IAAIA,KAAK,CAACD,IAAD,CAArB;AACH,GAvmBwB,CAwmBzB;;;AACApH,EAAAA,GAAG,CAACsH,KAAD,EAAQ;AACP,SAAKzI,WAAL,CAAiBmB,GAAjB,CAAqB,KAAK3C,QAA1B,EAAoCiK,KAApC;AACH;;AACDrB,EAAAA,YAAY,GAAG;AACX,SAAKpH,WAAL,CAAiB0I,MAAjB,CAAwB,KAAKlK,QAA7B;AACH;AACD;AACJ;AACA;;;AACI8J,EAAAA,UAAU,CAAC7B,IAAD,EAAO;AACb,QAAI,KAAKvH,YAAL,CAAkB2F,gBAAlB,CAAmC;AACnCP,MAAAA,IAAI,EAAEmC,IAAI,CAACjC,MADwB;AAEnCE,MAAAA,OAAO,EAAE+B,IAAI,CAAChC,UAFqB;AAGnCnB,MAAAA,IAAI,EAAEmD,IAAI,CAAChC;AAHwB,KAAnC,CAAJ,EAII;AACA,WAAKkE,mBAAL,CAAyBlC,IAAzB;AACA,aAAO,KAAP;AACH;;AACD,SAAK9E,IAAL,CAAU,UAAV,EAAsB8E,IAAtB;AACA,WAAO,IAAP;AACH;AACD;AACJ;AACA;;;AACIkC,EAAAA,mBAAmB,CAAClC,IAAD,EAAO;AACtB,QAAI,KAAK/J,UAAL,GAAkB,KAAKwC,YAAL,CAAkBmB,UAAxC,EAAoD;AAChD,UAAIoG,IAAI,CAACjC,MAAL,KAAgBrI,qBAAhB,IACA,KAAKa,sBAAL,KAAgC,CADpC,EACuC;AACnC,aAAKoE,cAAL;AACH,OAHD,MAIK;AACD,cAAMwH,UAAU,GAAG,KAAKC,aAAL,EAAnB;;AACA,YAAID,UAAU,IAAI,CAAlB,EAAqB;AACjB,eAAK1H,OAAL,CAAa,IAAIrD,KAAJ,CAAW,qCAAoC4I,IAAI,CAACjD,IAAK,EAAzD,CAAb;AACA;AACH,SALA,CAMD;AACA;;;AACA,aAAK/G,eAAL,IAAwB,KAAKQ,aAAL,CAAmBmF,UAA3C;AACA,aAAKR,kBAAL,CAAwB,KAAK3E,aAA7B;AACA,aAAKA,aAAL,GAAqBL,MAAM,CAACC,KAAP,CAAa,CAAb,CAArB,CAVC,CAWD;AACA;AACA;AACA;AACA;AACA;;AACA,aAAKgC,MAAL,GAAc9B,SAAd;AACA+L,QAAAA,UAAU,CAAC,KAAK9H,iBAAL,CAAuBtD,IAAvB,CAA4B,IAA5B,CAAD,EAAoCkL,UAApC,CAAV;AACH;;AACD,WAAKlM,UAAL;AACH,KA1BD,MA2BK;AACD,WAAKwE,OAAL,CAAa,IAAIrD,KAAJ,CAAU,4BAA4B4I,IAAI,CAACjD,IAA3C,CAAb;AACH;AACJ;AACD;AACJ;AACA;;;AACIqF,EAAAA,aAAa,GAAG;AACZ,UAAME,QAAQ,GAAGjD,IAAI,CAACkD,KAAL,CAAWlD,IAAI,CAACmD,MAAL,KAAgB,IAA3B,CAAjB;AACA,UAAMC,QAAQ,GAAGpD,IAAI,CAACqD,GAAL,CAAS,KAAKjK,YAAL,CAAkB8F,oBAA3B,EAAiD,KAAKtI,UAAtD,IACb,IADa,GAEbqM,QAFJ;AAGA,UAAMK,mBAAmB,GAAG,KAAKlK,YAAL,CAAkBkG,YAAlB,GAAiC,IAAjC,IACvB7E,IAAI,CAACC,GAAL,KAAa,KAAKF,kBADK,CAA5B;AAEA,UAAM+I,eAAe,GAAG,KAAKnK,YAAL,CAAkBgG,aAAlB,GAAkC,IAA1D;AACA,WAAOY,IAAI,CAACC,GAAL,CAASmD,QAAT,EAAmBG,eAAnB,EAAoCD,mBAApC,CAAP;AACH;AACD;AACJ;AACA;;;AACIjL,EAAAA,gBAAgB,CAACiF,GAAD,EAAM;AAClB,QAAI,CAAClI,OAAO,CAACK,cAAR,CAAuB6C,IAAvB,CAA4BgF,GAA5B,CAAL,EAAuC;AACnCA,MAAAA,GAAG,GAAI,WAAUA,GAAI,EAArB;AACH;;AACD,WAAOA,GAAG,CAACkG,OAAJ,CAAY,MAAZ,EAAoB,EAApB,CAAP,CAJkB,CAIc;AACnC;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACIpC,EAAAA,oBAAoB,CAAC1C,MAAD,EAAS;AACzB,WAAOA,MAAM,IAAI,GAAV,IAAiBA,MAAM,GAAG,GAAjC;AACH;;AA/rBwB;;AAisB7BtJ,OAAO,CAACI,MAAR,GAAiBA,MAAjB;;AACA,SAASD,MAAT,CAAgBmB,GAAhB,EAAqB;AACjB,SAAO,IAAIlB,MAAJ,CAAWkB,GAAX,CAAP;AACH;;AACDtB,OAAO,CAACG,MAAR,GAAiBA,MAAjB;;AACA,SAASD,SAAT,CAAmBoB,GAAnB,EAAwBsG,QAAxB,EAAkC;AAC9B,QAAMyG,EAAE,GAAG,IAAIjO,MAAJ,CAAWkB,GAAX,CAAX;;AACA,MAAI,CAACsG,QAAL,EAAe;AACX,WAAOyG,EAAE,CAACnO,SAAH,EAAP;AACH;;AACDmO,EAAAA,EAAE,CAACnO,SAAH,GAAe4H,IAAf,CAAoBC,CAAC,IAAIH,QAAQ,CAAC,IAAD,EAAOG,CAAP,CAAjC,EAA4CH,QAA5C;AACH;;AACD5H,OAAO,CAACE,SAAR,GAAoBA,SAApB","sourcesContent":["\"use strict\";\n// Copyright 2022 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createURI = exports.upload = exports.Upload = exports.PROTOCOL_REGEX = void 0;\nconst abort_controller_1 = require(\"abort-controller\");\nconst ConfigStore = require(\"configstore\");\nconst crypto_1 = require(\"crypto\");\nconst extend = require(\"extend\");\nconst gaxios = require(\"gaxios\");\nconst google_auth_library_1 = require(\"google-auth-library\");\nconst Pumpify = require(\"pumpify\");\nconst stream_1 = require(\"stream\");\nconst streamEvents = require(\"stream-events\");\nconst retry = require(\"async-retry\");\nconst NOT_FOUND_STATUS_CODE = 404;\nconst TERMINATED_UPLOAD_STATUS_CODE = 410;\nconst RESUMABLE_INCOMPLETE_STATUS_CODE = 308;\nconst DEFAULT_API_ENDPOINT_REGEX = /.*\\.googleapis\\.com/;\nexports.PROTOCOL_REGEX = /^(\\w*):\\/\\//;\nclass Upload extends Pumpify {\n    constructor(cfg) {\n        super();\n        this.numBytesWritten = 0;\n        this.numRetries = 0;\n        this.upstreamChunkBuffer = Buffer.alloc(0);\n        this.chunkBufferEncoding = undefined;\n        this.numChunksReadInRequest = 0;\n        /**\n         * A chunk used for caching the most recent upload chunk.\n         * We should not assume that the server received all bytes sent in the request.\n         *  - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n         */\n        this.lastChunkSent = Buffer.alloc(0);\n        this.upstreamEnded = false;\n        /** A stream representing the incoming data to upload */\n        this.upstream = new stream_1.Duplex({\n            read: async () => {\n                this.once('prepareFinish', () => {\n                    // Allows this (`Upload`) to finish/end once the upload has succeeded.\n                    this.upstream.push(null);\n                });\n            },\n            write: this.writeToChunkBuffer.bind(this),\n        });\n        streamEvents(this);\n        cfg = cfg || {};\n        if (!cfg.bucket || !cfg.file) {\n            throw new Error('A bucket and file name are required');\n        }\n        cfg.authConfig = cfg.authConfig || {};\n        cfg.authConfig.scopes = [\n            'https://www.googleapis.com/auth/devstorage.full_control',\n        ];\n        this.authClient = cfg.authClient || new google_auth_library_1.GoogleAuth(cfg.authConfig);\n        this.apiEndpoint = 'https://storage.googleapis.com';\n        if (cfg.apiEndpoint) {\n            this.apiEndpoint = this.sanitizeEndpoint(cfg.apiEndpoint);\n            if (!DEFAULT_API_ENDPOINT_REGEX.test(cfg.apiEndpoint)) {\n                this.authClient = gaxios;\n            }\n        }\n        this.baseURI = `${this.apiEndpoint}/upload/storage/v1/b`;\n        this.bucket = cfg.bucket;\n        const cacheKeyElements = [cfg.bucket, cfg.file];\n        if (typeof cfg.generation === 'number') {\n            cacheKeyElements.push(`${cfg.generation}`);\n        }\n        this.cacheKey = cacheKeyElements.join('/');\n        this.customRequestOptions = cfg.customRequestOptions || {};\n        this.file = cfg.file;\n        this.generation = cfg.generation;\n        this.kmsKeyName = cfg.kmsKeyName;\n        this.metadata = cfg.metadata || {};\n        this.offset = cfg.offset;\n        this.origin = cfg.origin;\n        this.params = cfg.params || {};\n        this.userProject = cfg.userProject;\n        this.chunkSize = cfg.chunkSize;\n        this.retryOptions = cfg.retryOptions;\n        if (cfg.key) {\n            /**\n             * NOTE: This is `as string` because there appears to be some weird kind\n             * of TypeScript bug as 2.8. Tracking the issue here:\n             * https://github.com/Microsoft/TypeScript/issues/23155\n             */\n            const base64Key = Buffer.from(cfg.key).toString('base64');\n            this.encryption = {\n                key: base64Key,\n                hash: crypto_1.createHash('sha256').update(cfg.key).digest('base64'),\n            };\n        }\n        this.predefinedAcl = cfg.predefinedAcl;\n        if (cfg.private)\n            this.predefinedAcl = 'private';\n        if (cfg.public)\n            this.predefinedAcl = 'publicRead';\n        const configPath = cfg.configPath;\n        this.configStore = new ConfigStore('gcs-resumable-upload', null, {\n            configPath,\n        });\n        const autoRetry = cfg.retryOptions.autoRetry;\n        this.uriProvidedManually = !!cfg.uri;\n        this.uri = cfg.uri || this.get('uri');\n        this.numBytesWritten = 0;\n        this.numRetries = 0; //counter for number of retries currently executed\n        if (!autoRetry) {\n            cfg.retryOptions.maxRetries = 0;\n        }\n        this.timeOfFirstRequest = Date.now();\n        const contentLength = cfg.metadata\n            ? Number(cfg.metadata.contentLength)\n            : NaN;\n        this.contentLength = isNaN(contentLength) ? '*' : contentLength;\n        this.upstream.on('end', () => {\n            this.upstreamEnded = true;\n        });\n        this.on('prefinish', () => {\n            this.upstreamEnded = true;\n        });\n        this.once('writing', () => {\n            // Now that someone is writing to this object, let's attach\n            // some duplexes. These duplexes enable this object to be\n            // better managed in terms of 'end'/'finish' control and\n            // buffering writes downstream if someone enables multi-\n            // chunk upload support (`chunkSize`) w/o adding too much into\n            // memory.\n            this.setPipeline(this.upstream, new stream_1.PassThrough());\n            if (this.uri) {\n                this.continueUploading();\n            }\n            else {\n                this.createURI((err, uri) => {\n                    if (err) {\n                        return this.destroy(err);\n                    }\n                    this.set({ uri });\n                    this.startUploading();\n                    return;\n                });\n            }\n        });\n    }\n    /**\n     * A handler for `upstream` to write and buffer its data.\n     *\n     * @param chunk The chunk to append to the buffer\n     * @param encoding The encoding of the chunk\n     * @param readCallback A callback for when the buffer has been read downstream\n     */\n    writeToChunkBuffer(chunk, encoding, readCallback) {\n        this.upstreamChunkBuffer = Buffer.concat([\n            this.upstreamChunkBuffer,\n            typeof chunk === 'string' ? Buffer.from(chunk, encoding) : chunk,\n        ]);\n        this.chunkBufferEncoding = encoding;\n        this.once('readFromChunkBuffer', readCallback);\n        process.nextTick(() => this.emit('wroteToChunkBuffer'));\n    }\n    /**\n     * Prepends data back to the upstream chunk buffer.\n     *\n     * @param chunk The data to prepend\n     */\n    unshiftChunkBuffer(chunk) {\n        this.upstreamChunkBuffer = Buffer.concat([chunk, this.upstreamChunkBuffer]);\n    }\n    /**\n     * Retrieves data from upstream's buffer.\n     *\n     * @param limit The maximum amount to return from the buffer.\n     * @returns The data requested.\n     */\n    pullFromChunkBuffer(limit) {\n        const chunk = this.upstreamChunkBuffer.slice(0, limit);\n        this.upstreamChunkBuffer = this.upstreamChunkBuffer.slice(limit);\n        // notify upstream we've read from the buffer so it can potentially\n        // send more data down.\n        process.nextTick(() => this.emit('readFromChunkBuffer'));\n        return chunk;\n    }\n    /**\n     * A handler for determining if data is ready to be read from upstream.\n     *\n     * @returns If there will be more chunks to read in the future\n     */\n    async waitForNextChunk() {\n        const willBeMoreChunks = await new Promise(resolve => {\n            // There's data available - it should be digested\n            if (this.upstreamChunkBuffer.byteLength) {\n                return resolve(true);\n            }\n            // The upstream writable ended, we shouldn't expect any more data.\n            if (this.upstreamEnded) {\n                return resolve(false);\n            }\n            // Nothing immediate seems to be determined. We need to prepare some\n            // listeners to determine next steps...\n            const wroteToChunkBufferCallback = () => {\n                removeListeners();\n                return resolve(true);\n            };\n            const upstreamFinishedCallback = () => {\n                removeListeners();\n                // this should be the last chunk, if there's anything there\n                if (this.upstreamChunkBuffer.length)\n                    return resolve(true);\n                return resolve(false);\n            };\n            // Remove listeners when we're ready to callback.\n            // It's important to clean-up listeners as Node has a default max number of\n            // event listeners. Notably, The number of requests can be greater than the\n            // number of potential listeners.\n            // - https://nodejs.org/api/events.html#eventsdefaultmaxlisteners\n            const removeListeners = () => {\n                this.removeListener('wroteToChunkBuffer', wroteToChunkBufferCallback);\n                this.upstream.removeListener('finish', upstreamFinishedCallback);\n                this.removeListener('prefinish', upstreamFinishedCallback);\n            };\n            // If there's data recently written it should be digested\n            this.once('wroteToChunkBuffer', wroteToChunkBufferCallback);\n            // If the upstream finishes let's see if there's anything to grab\n            this.upstream.once('finish', upstreamFinishedCallback);\n            this.once('prefinish', upstreamFinishedCallback);\n        });\n        return willBeMoreChunks;\n    }\n    /**\n     * Reads data from upstream up to the provided `limit`.\n     * Ends when the limit has reached or no data is expected to be pushed from upstream.\n     *\n     * @param limit The most amount of data this iterator should return. `Infinity` by default.\n     * @param oneChunkMode Determines if one, exhaustive chunk is yielded for the iterator\n     */\n    async *upstreamIterator(limit = Infinity, oneChunkMode) {\n        let completeChunk = Buffer.alloc(0);\n        // read from upstream chunk buffer\n        while (limit && (await this.waitForNextChunk())) {\n            // read until end or limit has been reached\n            const chunk = this.pullFromChunkBuffer(limit);\n            limit -= chunk.byteLength;\n            if (oneChunkMode) {\n                // return 1 chunk at the end of iteration\n                completeChunk = Buffer.concat([completeChunk, chunk]);\n            }\n            else {\n                // return many chunks throughout iteration\n                yield {\n                    chunk,\n                    encoding: this.chunkBufferEncoding,\n                };\n            }\n        }\n        if (oneChunkMode) {\n            yield {\n                chunk: completeChunk,\n                encoding: this.chunkBufferEncoding,\n            };\n        }\n    }\n    createURI(callback) {\n        if (!callback) {\n            return this.createURIAsync();\n        }\n        this.createURIAsync().then(r => callback(null, r), callback);\n    }\n    async createURIAsync() {\n        const metadata = this.metadata;\n        const reqOpts = {\n            method: 'POST',\n            url: [this.baseURI, this.bucket, 'o'].join('/'),\n            params: Object.assign({\n                name: this.file,\n                uploadType: 'resumable',\n            }, this.params),\n            data: metadata,\n            headers: {},\n        };\n        if (metadata.contentLength) {\n            reqOpts.headers['X-Upload-Content-Length'] =\n                metadata.contentLength.toString();\n        }\n        if (metadata.contentType) {\n            reqOpts.headers['X-Upload-Content-Type'] = metadata.contentType;\n        }\n        if (typeof this.generation !== 'undefined') {\n            reqOpts.params.ifGenerationMatch = this.generation;\n        }\n        if (this.kmsKeyName) {\n            reqOpts.params.kmsKeyName = this.kmsKeyName;\n        }\n        if (this.predefinedAcl) {\n            reqOpts.params.predefinedAcl = this.predefinedAcl;\n        }\n        if (this.origin) {\n            reqOpts.headers.Origin = this.origin;\n        }\n        const uri = await retry(async (bail) => {\n            var _a, _b, _c;\n            try {\n                const res = await this.makeRequest(reqOpts);\n                return res.headers.location;\n            }\n            catch (err) {\n                const e = err;\n                const apiError = {\n                    code: (_a = e.response) === null || _a === void 0 ? void 0 : _a.status,\n                    name: (_b = e.response) === null || _b === void 0 ? void 0 : _b.statusText,\n                    message: (_c = e.response) === null || _c === void 0 ? void 0 : _c.statusText,\n                    errors: [\n                        {\n                            reason: e.code,\n                        },\n                    ],\n                };\n                if (this.retryOptions.maxRetries > 0 &&\n                    this.retryOptions.retryableErrorFn(apiError)) {\n                    throw e;\n                }\n                else {\n                    return bail(e);\n                }\n            }\n        }, {\n            retries: this.retryOptions.maxRetries,\n            factor: this.retryOptions.retryDelayMultiplier,\n            maxTimeout: this.retryOptions.maxRetryDelay * 1000,\n            maxRetryTime: this.retryOptions.totalTimeout * 1000,\n        });\n        this.uri = uri;\n        this.offset = 0;\n        return uri;\n    }\n    async continueUploading() {\n        if (typeof this.offset === 'number') {\n            this.startUploading();\n            return;\n        }\n        await this.getAndSetOffset();\n        this.startUploading();\n    }\n    async startUploading() {\n        const multiChunkMode = !!this.chunkSize;\n        let responseReceived = false;\n        this.numChunksReadInRequest = 0;\n        if (!this.offset) {\n            this.offset = 0;\n        }\n        // Check if we're uploading the expected object\n        if (this.numBytesWritten === 0) {\n            const isSameObject = await this.ensureUploadingSameObject();\n            if (!isSameObject) {\n                // `ensureUploadingSameObject` will restart the upload.\n                return;\n            }\n        }\n        // Check if the offset (server) is too far behind the current stream\n        if (this.offset < this.numBytesWritten) {\n            this.emit('error', new RangeError('The offset is lower than the number of bytes written'));\n            return;\n        }\n        // Check if we should 'fast-forward' to the relevant data to upload\n        if (this.numBytesWritten < this.offset) {\n            // 'fast-forward' to the byte where we need to upload.\n            // only push data from the byte after the one we left off on\n            const fastForwardBytes = this.offset - this.numBytesWritten;\n            for await (const _chunk of this.upstreamIterator(fastForwardBytes)) {\n                _chunk; // discard the data up until the point we want\n            }\n            this.numBytesWritten = this.offset;\n        }\n        let expectedUploadSize = undefined;\n        // Set `expectedUploadSize` to `contentLength` if available\n        if (typeof this.contentLength === 'number') {\n            expectedUploadSize = this.contentLength - this.numBytesWritten;\n        }\n        // `expectedUploadSize` should be no more than the `chunkSize`.\n        // It's possible this is the last chunk request for a multiple\n        // chunk upload, thus smaller than the chunk size.\n        if (this.chunkSize) {\n            expectedUploadSize = expectedUploadSize\n                ? Math.min(this.chunkSize, expectedUploadSize)\n                : this.chunkSize;\n        }\n        // A queue for the upstream data\n        const upstreamQueue = this.upstreamIterator(expectedUploadSize, multiChunkMode // multi-chunk mode should return 1 chunk per request\n        );\n        // The primary read stream for this request. This stream retrieves no more\n        // than the exact requested amount from upstream.\n        const requestStream = new stream_1.Readable({\n            read: async () => {\n                // Don't attempt to retrieve data upstream if we already have a response\n                if (responseReceived)\n                    requestStream.push(null);\n                const result = await upstreamQueue.next();\n                if (result.value) {\n                    this.numChunksReadInRequest++;\n                    this.lastChunkSent = result.value.chunk;\n                    this.numBytesWritten += result.value.chunk.byteLength;\n                    this.emit('progress', {\n                        bytesWritten: this.numBytesWritten,\n                        contentLength: this.contentLength,\n                    });\n                    requestStream.push(result.value.chunk, result.value.encoding);\n                }\n                if (result.done) {\n                    requestStream.push(null);\n                }\n            },\n        });\n        let headers = {};\n        // If using multiple chunk upload, set appropriate header\n        if (multiChunkMode && expectedUploadSize) {\n            // The '-1' is because the ending byte is inclusive in the request.\n            const endingByte = expectedUploadSize + this.numBytesWritten - 1;\n            headers = {\n                'Content-Length': expectedUploadSize,\n                'Content-Range': `bytes ${this.offset}-${endingByte}/${this.contentLength}`,\n            };\n        }\n        else {\n            headers = {\n                'Content-Range': `bytes ${this.offset}-*/${this.contentLength}`,\n            };\n        }\n        const reqOpts = {\n            method: 'PUT',\n            url: this.uri,\n            headers,\n            body: requestStream,\n        };\n        try {\n            const resp = await this.makeRequestStream(reqOpts);\n            if (resp) {\n                responseReceived = true;\n                this.responseHandler(resp);\n            }\n        }\n        catch (err) {\n            const e = err;\n            this.destroy(e);\n        }\n    }\n    // Process the API response to look for errors that came in\n    // the response body.\n    responseHandler(resp) {\n        if (resp.data.error) {\n            this.destroy(resp.data.error);\n            return;\n        }\n        const shouldContinueWithNextMultiChunkRequest = this.chunkSize &&\n            resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE &&\n            resp.headers.range;\n        if (shouldContinueWithNextMultiChunkRequest) {\n            // Use the upper value in this header to determine where to start the next chunk.\n            // We should not assume that the server received all bytes sent in the request.\n            // https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n            const range = resp.headers.range;\n            this.offset = Number(range.split('-')[1]) + 1;\n            // We should not assume that the server received all bytes sent in the request.\n            // - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload\n            const missingBytes = this.numBytesWritten - this.offset;\n            if (missingBytes) {\n                const dataToPrependForResending = this.lastChunkSent.slice(-missingBytes);\n                // As multi-chunk uploads send one chunk per request and pulls one\n                // chunk into the pipeline, prepending the missing bytes back should\n                // be fine for the next request.\n                this.unshiftChunkBuffer(dataToPrependForResending);\n                this.numBytesWritten -= missingBytes;\n                this.lastChunkSent = Buffer.alloc(0);\n            }\n            // continue uploading next chunk\n            this.continueUploading();\n        }\n        else if (!this.isSuccessfulResponse(resp.status)) {\n            const err = {\n                code: resp.status,\n                name: 'Upload failed',\n                message: 'Upload failed',\n            };\n            this.destroy(err);\n        }\n        else {\n            // remove the last chunk sent\n            this.lastChunkSent = Buffer.alloc(0);\n            if (resp && resp.data) {\n                resp.data.size = Number(resp.data.size);\n            }\n            this.emit('metadata', resp.data);\n            this.deleteConfig();\n            // Allow the object (Upload) to continue naturally so the user's\n            // \"finish\" event fires.\n            this.emit('prepareFinish');\n        }\n    }\n    /**\n     * Check if this is the same content uploaded previously. This caches a\n     * slice of the first chunk, then compares it with the first byte of\n     * incoming data.\n     *\n     * @returns if the request is ok to continue as-is\n     */\n    async ensureUploadingSameObject() {\n        // A queue for the upstream data\n        const upstreamQueue = this.upstreamIterator(16, true // we just want one chunk for this validation\n        );\n        const upstreamChunk = await upstreamQueue.next();\n        const chunk = upstreamChunk.value\n            ? upstreamChunk.value.chunk\n            : Buffer.alloc(0);\n        // Put the original chunk back into the buffer as we just wanted to 'peek'\n        // at the stream for validation.\n        this.unshiftChunkBuffer(chunk);\n        let cachedFirstChunk = this.get('firstChunk');\n        const firstChunk = chunk.valueOf();\n        if (!cachedFirstChunk) {\n            // This is a new upload. Cache the first chunk.\n            this.set({ uri: this.uri, firstChunk });\n        }\n        else {\n            // this continues an upload in progress. check if the bytes are the same\n            cachedFirstChunk = Buffer.from(cachedFirstChunk);\n            const nextChunk = Buffer.from(firstChunk);\n            if (Buffer.compare(cachedFirstChunk, nextChunk) !== 0) {\n                // this data is not the same. start a new upload\n                this.restart();\n                return false;\n            }\n        }\n        return true;\n    }\n    async getAndSetOffset() {\n        const opts = {\n            method: 'PUT',\n            url: this.uri,\n            headers: { 'Content-Length': 0, 'Content-Range': 'bytes */*' },\n        };\n        try {\n            const resp = await this.makeRequest(opts);\n            if (resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE) {\n                if (resp.headers.range) {\n                    const range = resp.headers.range;\n                    this.offset = Number(range.split('-')[1]) + 1;\n                    return;\n                }\n            }\n            this.offset = 0;\n        }\n        catch (e) {\n            const err = e;\n            const resp = err.response;\n            // we don't return a 404 to the user if they provided the resumable\n            // URI. if we're just using the configstore file to tell us that this\n            // file exists, and it turns out that it doesn't (the 404), that's\n            // probably stale config data.\n            if (resp &&\n                resp.status === NOT_FOUND_STATUS_CODE &&\n                !this.uriProvidedManually) {\n                this.restart();\n                return;\n            }\n            // this resumable upload is unrecoverable (bad data or service error).\n            //  -\n            //  https://github.com/googleapis/gcs-resumable-upload/issues/15\n            //  -\n            //  https://github.com/googleapis/gcs-resumable-upload/pull/16#discussion_r80363774\n            if (resp && resp.status === TERMINATED_UPLOAD_STATUS_CODE) {\n                this.restart();\n                return;\n            }\n            this.destroy(err);\n        }\n    }\n    async makeRequest(reqOpts) {\n        if (this.encryption) {\n            reqOpts.headers = reqOpts.headers || {};\n            reqOpts.headers['x-goog-encryption-algorithm'] = 'AES256';\n            reqOpts.headers['x-goog-encryption-key'] = this.encryption.key.toString();\n            reqOpts.headers['x-goog-encryption-key-sha256'] =\n                this.encryption.hash.toString();\n        }\n        if (this.userProject) {\n            reqOpts.params = reqOpts.params || {};\n            reqOpts.params.userProject = this.userProject;\n        }\n        // Let gaxios know we will handle a 308 error code ourselves.\n        reqOpts.validateStatus = (status) => {\n            return (this.isSuccessfulResponse(status) ||\n                status === RESUMABLE_INCOMPLETE_STATUS_CODE);\n        };\n        const combinedReqOpts = extend(true, {}, this.customRequestOptions, reqOpts);\n        const res = await this.authClient.request(combinedReqOpts);\n        if (res.data && res.data.error) {\n            throw res.data.error;\n        }\n        return res;\n    }\n    async makeRequestStream(reqOpts) {\n        const controller = new abort_controller_1.default();\n        const errorCallback = () => controller.abort();\n        this.once('error', errorCallback);\n        if (this.userProject) {\n            reqOpts.params = reqOpts.params || {};\n            reqOpts.params.userProject = this.userProject;\n        }\n        reqOpts.signal = controller.signal;\n        reqOpts.validateStatus = () => true;\n        const combinedReqOpts = extend(true, {}, this.customRequestOptions, reqOpts);\n        const res = await this.authClient.request(combinedReqOpts);\n        const successfulRequest = this.onResponse(res);\n        this.removeListener('error', errorCallback);\n        return successfulRequest ? res : null;\n    }\n    restart() {\n        if (this.numBytesWritten) {\n            let message = 'Attempting to restart an upload after unrecoverable bytes have been written from upstream. ';\n            message += 'Stopping as this could result in data loss. ';\n            message += 'Create a new upload object to continue.';\n            this.emit('error', new RangeError(message));\n            return;\n        }\n        this.lastChunkSent = Buffer.alloc(0);\n        this.deleteConfig();\n        this.createURI((err, uri) => {\n            if (err) {\n                return this.destroy(err);\n            }\n            this.set({ uri });\n            this.startUploading();\n            return;\n        });\n    }\n    get(prop) {\n        const store = this.configStore.get(this.cacheKey);\n        return store && store[prop];\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    set(props) {\n        this.configStore.set(this.cacheKey, props);\n    }\n    deleteConfig() {\n        this.configStore.delete(this.cacheKey);\n    }\n    /**\n     * @return {bool} is the request good?\n     */\n    onResponse(resp) {\n        if (this.retryOptions.retryableErrorFn({\n            code: resp.status,\n            message: resp.statusText,\n            name: resp.statusText,\n        })) {\n            this.attemptDelayedRetry(resp);\n            return false;\n        }\n        this.emit('response', resp);\n        return true;\n    }\n    /**\n     * @param resp GaxiosResponse object from previous attempt\n     */\n    attemptDelayedRetry(resp) {\n        if (this.numRetries < this.retryOptions.maxRetries) {\n            if (resp.status === NOT_FOUND_STATUS_CODE &&\n                this.numChunksReadInRequest === 0) {\n                this.startUploading();\n            }\n            else {\n                const retryDelay = this.getRetryDelay();\n                if (retryDelay <= 0) {\n                    this.destroy(new Error(`Retry total time limit exceeded - ${resp.data}`));\n                    return;\n                }\n                // Unshift the most recent chunk back in case it's needed for the next\n                // request.\n                this.numBytesWritten -= this.lastChunkSent.byteLength;\n                this.unshiftChunkBuffer(this.lastChunkSent);\n                this.lastChunkSent = Buffer.alloc(0);\n                // We don't know how much data has been received by the server.\n                // `continueUploading` will recheck the offset via `getAndSetOffset`.\n                // If `offset` < `numberBytesReceived` then we will raise a RangeError\n                // as we've streamed too much data that has been missed - this should\n                // not be the case for multi-chunk uploads as `lastChunkSent` is the\n                // body of the entire request.\n                this.offset = undefined;\n                setTimeout(this.continueUploading.bind(this), retryDelay);\n            }\n            this.numRetries++;\n        }\n        else {\n            this.destroy(new Error('Retry limit exceeded - ' + resp.data));\n        }\n    }\n    /**\n     * @returns {number} the amount of time to wait before retrying the request\n     */\n    getRetryDelay() {\n        const randomMs = Math.round(Math.random() * 1000);\n        const waitTime = Math.pow(this.retryOptions.retryDelayMultiplier, this.numRetries) *\n            1000 +\n            randomMs;\n        const maxAllowableDelayMs = this.retryOptions.totalTimeout * 1000 -\n            (Date.now() - this.timeOfFirstRequest);\n        const maxRetryDelayMs = this.retryOptions.maxRetryDelay * 1000;\n        return Math.min(waitTime, maxRetryDelayMs, maxAllowableDelayMs);\n    }\n    /*\n     * Prepare user-defined API endpoint for compatibility with our API.\n     */\n    sanitizeEndpoint(url) {\n        if (!exports.PROTOCOL_REGEX.test(url)) {\n            url = `https://${url}`;\n        }\n        return url.replace(/\\/+$/, ''); // Remove trailing slashes\n    }\n    /**\n     * Check if a given status code is 2xx\n     *\n     * @param status The status code to check\n     * @returns if the status is 2xx\n     */\n    isSuccessfulResponse(status) {\n        return status >= 200 && status < 300;\n    }\n}\nexports.Upload = Upload;\nfunction upload(cfg) {\n    return new Upload(cfg);\n}\nexports.upload = upload;\nfunction createURI(cfg, callback) {\n    const up = new Upload(cfg);\n    if (!callback) {\n        return up.createURI();\n    }\n    up.createURI().then(r => callback(null, r), callback);\n}\nexports.createURI = createURI;\n//# sourceMappingURL=index.js.map"]},"metadata":{},"sourceType":"script"}